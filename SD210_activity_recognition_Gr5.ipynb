{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SD210_activity_recognition_Gr5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-AT8mMrkaDnp",
        "Q5E98nhDARh1",
        "sxFrWQM7AyOs",
        "iE3BuhobA3ak",
        "9A-M_IodAkl1",
        "m2qe6BkNFLxf",
        "aIMz_0fuGnZn",
        "GtJEIj0UHEKX",
        "31h1wrwtH7JX",
        "t0wfH46xIGFB",
        "8JpYuIdo0gQb",
        "2uFkBJmpHPD9",
        "Tg-ZKgtYJX-T",
        "P0ZMjA9vJX-U",
        "FRBOm6jz0yj3",
        "zCF1e6LnHFlv",
        "eU7LpNxPWA37",
        "kMm9BFtNJ20a",
        "vopQQ_vxJ20b",
        "emUXJBCg1-sb",
        "0Wix_NHmYZT-",
        "pK0_Cemg2cJh"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFa91qWr1p7O",
        "outputId": "dcebce95-1992-4921-de27-c07ccaa3a131"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "  gdd.download_file_from_google_drive(file_id='12c6JmFk_NR0jIQHNzYX4AyLQH2ljYqk_',\n",
        "  dest_path='./data.txt')\n",
        "  gdd.download_file_from_google_drive(file_id='10sJq8V5GyMEWAC2dwFY-L8yO5YgXPKJd',\n",
        "  dest_path='./labels.txt')\n",
        "else:\n",
        "  print('You are not using Colab. Please define working_dir with the absolute path to the folder where you downloaded the data')\n",
        "\n",
        "# Please modify working_dir only if you are using your Anaconda (and not Google Colab)\n",
        "# You should write the absolute path of your working directory with the data\n",
        "Working_directory=\"./\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 12c6JmFk_NR0jIQHNzYX4AyLQH2ljYqk_ into ./data.txt... Done.\n",
            "Downloading 10sJq8V5GyMEWAC2dwFY-L8yO5YgXPKJd into ./labels.txt... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obj7e81s26AX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import paired_distances\n",
        "from sklearn.model_selection import  cross_val_score, cross_validate, GridSearchCV, KFold, StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import decomposition\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "# this is needed to plot figures within the notebook\n",
        "%matplotlib inline \n",
        "np.random.seed(seed=666)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AT8mMrkaDnp"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO3vdsKA95oL",
        "outputId": "e66dc5ed-1352-4e06-e5ce-ffbf87e40a91"
      },
      "source": [
        "feature_name = pd.read_csv('labels.txt',header=None,sep=\"/\").values\n",
        "feature_name = feature_name.reshape(-1)\n",
        "print(feature_name.shape)\n",
        "print(feature_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(535,)\n",
            "['Subject index (1-40)' 'ECG_original_mean' 'ECG_original_std'\n",
            " 'ECG_original_trimmean25' 'ECG_original_median' 'ECG_original_skewness'\n",
            " 'ECG_original_kurtosis' 'ECG_original_max' 'ECG_original_min'\n",
            " 'ECG_original_prctile25' 'ECG_original_prctile75'\n",
            " 'ECG_original_geomean(abs)' 'ECG_original_harmmean' 'ECG_original_mad'\n",
            " 'ECG_original_baseline' 'ECG_RR_window_mean' 'ECG_RR_window_std'\n",
            " 'ECG_RR_window_trimmean25' 'ECG_RR_window_median'\n",
            " 'ECG_RR_window_skewness' 'ECG_RR_window_kurtosis' 'ECG_RR_window_max'\n",
            " 'ECG_RR_window_min' 'ECG_RR_window_prctile25' 'ECG_RR_window_prctile75'\n",
            " 'ECG_RR_window_geomean(abs)' 'ECG_RR_window_harmmean' 'ECG_RR_window_mad'\n",
            " 'ECG_RR_window_baseline' 'ECG_amplitude_RR_mean' 'ECG_amplitude_RR_std'\n",
            " 'ECG_amplitude_RR_trimmean25' 'ECG_amplitude_RR_median'\n",
            " 'ECG_amplitude_RR_skewness' 'ECG_amplitude_RR_kurtosis'\n",
            " 'ECG_amplitude_RR_max' 'ECG_amplitude_RR_min'\n",
            " 'ECG_amplitude_RR_prctile25' 'ECG_amplitude_RR_prctile75'\n",
            " 'ECG_amplitude_RR_geomean(abs)' 'ECG_amplitude_RR_harmmean'\n",
            " 'ECG_amplitude_RR_mad' 'ECG_amplitude_RR_baseline' 'ECG_HR_min_div_mean'\n",
            " 'ECG_HR_min_div_std' 'ECG_HR_min_div_trimmean25' 'ECG_HR_min_div_median'\n",
            " 'ECG_HR_min_div_skewness' 'ECG_HR_min_div_kurtosis' 'ECG_HR_min_div_max'\n",
            " 'ECG_HR_min_div_min' 'ECG_HR_min_div_prctile25'\n",
            " 'ECG_HR_min_div_prctile75' 'ECG_HR_min_div_geomean(abs)'\n",
            " 'ECG_HR_min_div_harmmean' 'ECG_HR_min_div_mad' 'ECG_HR_min_div_baseline'\n",
            " 'ECG_DBD' 'ECG_EI' 'ECG_IE' 'ECG_Logstd' 'ECG_RSAindex' 'ECG_M'\n",
            " 'ECG_Load_index' 'ECG_NN50' 'ECG_pNN50' 'ECG_Entropyaprox' 'ECG_hrv_mean'\n",
            " 'ECG_hrv_std' 'ECG_hrv_trimmean25' 'ECG_hrv_median' 'ECG_hrv_skewness'\n",
            " 'ECG_hrv_kurtosis' 'ECG_hrv_max' 'ECG_hrv_min' 'ECG_hrv_prctile25'\n",
            " 'ECG_hrv_prctile75' 'ECG_hrv_geomean(abs)' 'ECG_hrv_harmmean'\n",
            " 'ECG_hrv_mad' 'ECG_hrv_baseline' 'ECG_PSD_mean' 'ECG_PSD_std'\n",
            " 'ECG_PSD_trimmean25' 'ECG_PSD_median' 'ECG_PSD_skewness'\n",
            " 'ECG_PSD_kurtosis' 'ECG_PSD_max' 'ECG_PSD_min' 'ECG_PSD_prctile25'\n",
            " 'ECG_PSD_prctile75' 'ECG_PSD_geomean(abs)' 'ECG_PSD_harmmean'\n",
            " 'ECG_PSD_mad' 'ECG_PSD_baseline' 'ECG_p_VFL_mean' 'ECG_p_VFL_std'\n",
            " 'ECG_p_VFL_trimmean25' 'ECG_p_VFL_median' 'ECG_p_VFL_skewness'\n",
            " 'ECG_p_VFL_kurtosis' 'ECG_p_VFL_max' 'ECG_p_VFL_min'\n",
            " 'ECG_p_VFL_prctile25' 'ECG_p_VFL_prctile75' 'ECG_p_VFL_geomean(abs)'\n",
            " 'ECG_p_VFL_harmmean' 'ECG_p_VFL_mad' 'ECG_p_VFL_baseline' 'ECG_p_LF_mean'\n",
            " 'ECG_p_LF_std' 'ECG_p_LF_trimmean25' 'ECG_p_LF_median'\n",
            " 'ECG_p_LF_skewness' 'ECG_p_LF_kurtosis' 'ECG_p_LF_max' 'ECG_p_LF_min'\n",
            " 'ECG_p_LF_prctile25' 'ECG_p_LF_prctile75' 'ECG_p_LF_geomean(abs)'\n",
            " 'ECG_p_LF_harmmean' 'ECG_p_LF_mad' 'ECG_p_LF_baseline' 'ECG_p_MF_mean'\n",
            " 'ECG_p_MF_std' 'ECG_p_MF_trimmean25' 'ECG_p_MF_median'\n",
            " 'ECG_p_MF_skewness' 'ECG_p_MF_kurtosis' 'ECG_p_MF_max' 'ECG_p_MF_min'\n",
            " 'ECG_p_MF_prctile25' 'ECG_p_MF_prctile75' 'ECG_p_MF_geomean(abs)'\n",
            " 'ECG_p_MF_harmmean' 'ECG_p_MF_mad' 'ECG_p_MF_baseline' 'ECG_p_HF_mean'\n",
            " 'ECG_p_HF_std' 'ECG_p_HF_trimmean25' 'ECG_p_HF_median'\n",
            " 'ECG_p_HF_skewness' 'ECG_p_HF_kurtosis' 'ECG_p_HF_max' 'ECG_p_HF_min'\n",
            " 'ECG_p_HF_prctile25' 'ECG_p_HF_prctile75' 'ECG_p_HF_geomean(abs)'\n",
            " 'ECG_p_HF_harmmean' 'ECG_p_HF_mad' 'ECG_p_HF_baseline'\n",
            " 'ECG_p_total_LF_mean' 'ECG_p_total_LF_std' 'ECG_p_total_LF_trimmean25'\n",
            " 'ECG_p_total_LF_median' 'ECG_p_total_LF_skewness'\n",
            " 'ECG_p_total_LF_kurtosis' 'ECG_p_total_LF_max' 'ECG_p_total_LF_min'\n",
            " 'ECG_p_total_LF_prctile25' 'ECG_p_total_LF_prctile75'\n",
            " 'ECG_p_total_LF_geomean(abs)' 'ECG_p_total_LF_harmmean'\n",
            " 'ECG_p_total_LF_mad' 'ECG_p_total_LF_baseline' 'ECG_HF_LF' 'ECG_LF_HF'\n",
            " 'ECG_MF_HF' 'ECG_HF_TF' 'ECG_LF_MF_HF' 'ECG_CCV_LF' 'ECG_CCV_HF'\n",
            " 'ECG_RMSSDD' 'ECG_A1_DFA' 'ECG_A2_DFA' 'IT_Original_mean'\n",
            " 'IT_Original_std' 'IT_Original_trimmean25' 'IT_Original_median'\n",
            " 'IT_Original_skewness' 'IT_Original_kurtosis' 'IT_Original_max'\n",
            " 'IT_Original_min' 'IT_Original_prctile25' 'IT_Original_prctile75'\n",
            " 'IT_Original_geomean(abs)' 'IT_Original_harmmean' 'IT_Original_mad'\n",
            " 'IT_Original_baseline' 'IT_Original_Area' 'IT_LF_mean' 'IT_LF_std'\n",
            " 'IT_LF_trimmean25' 'IT_LF_median' 'IT_LF_skewness' 'IT_LF_kurtosis'\n",
            " 'IT_LF_max' 'IT_LF_min' 'IT_LF_prctile25' 'IT_LF_prctile75'\n",
            " 'IT_LF_geomean(abs)' 'IT_LF_harmmean' 'IT_LF_mad' 'IT_LF_baseline'\n",
            " 'IT_LF_Area' 'IT_RF_mean' 'IT_RF_std' 'IT_RF_trimmean25' 'IT_RF_median'\n",
            " 'IT_RF_skewness' 'IT_RF_kurtosis' 'IT_RF_max' 'IT_RF_min'\n",
            " 'IT_RF_prctile25' 'IT_RF_prctile75' 'IT_RF_geomean(abs)' 'IT_RF_harmmean'\n",
            " 'IT_RF_mad' 'IT_RF_baseline' 'IT_RF_Area' 'IT_BR_mean' 'IT_BRV_mean'\n",
            " 'IT_BRV_std' 'IT_BRV_trimmean25' 'IT_BRV_median' 'IT_BRV_skewness'\n",
            " 'IT_BRV_kurtosis' 'IT_BRV_max' 'IT_BRV_min' 'IT_BRV_prctile25'\n",
            " 'IT_BRV_prctile75' 'IT_BRV_geomean(abs)' 'IT_BRV_harmmean' 'IT_BRV_mad'\n",
            " 'IT_BRV_baseline' 'IT_PSD_mean' 'IT_PSD_std' 'IT_PSD_trimmean25'\n",
            " 'IT_PSD_median' 'IT_PSD_skewness' 'IT_PSD_kurtosis' 'IT_PSD_max'\n",
            " 'IT_PSD_min' 'IT_PSD_prctile25' 'IT_PSD_prctile75' 'IT_PSD_geomean(abs)'\n",
            " 'IT_PSD_harmmean' 'IT_PSD_mad' 'IT_PSD_baseline' 'IT_VLF_mean'\n",
            " 'IT_VLF_std' 'IT_VLF_trimmean25' 'IT_VLF_median' 'IT_VLF_skewness'\n",
            " 'IT_VLF_kurtosis' 'IT_VLF_max' 'IT_VLF_min' 'IT_VLF_prctile25'\n",
            " 'IT_VLF_prctile75' 'IT_VLF_geomean(abs)' 'IT_VLF_harmmean' 'IT_VLF_mad'\n",
            " 'IT_VLF_baseline' 'IT_LF_mean' 'IT_LF_std' 'IT_LF_trimmean25'\n",
            " 'IT_LF_median' 'IT_LF_skewness' 'IT_LF_kurtosis' 'IT_LF_max' 'IT_LF_min'\n",
            " 'IT_LF_prctile25' 'IT_LF_prctile75' 'IT_LF_geomean(abs)' 'IT_LF_harmmean'\n",
            " 'IT_LF_mad' 'IT_LF_baseline' 'IT_MF_mean' 'IT_MF_std' 'IT_MF_trimmean25'\n",
            " 'IT_MF_median' 'IT_MF_skewness' 'IT_MF_kurtosis' 'IT_MF_max' 'IT_MF_min'\n",
            " 'IT_MF_prctile25' 'IT_MF_prctile75' 'IT_MF_geomean(abs)' 'IT_MF_harmmean'\n",
            " 'IT_MF_mad' 'IT_MF_baseline' 'IT_HF_mean' 'IT_HF_std' 'IT_HF_trimmean25'\n",
            " 'IT_HF_median' 'IT_HF_skewness' 'IT_HF_kurtosis' 'IT_HF_max' 'IT_HF_min'\n",
            " 'IT_HF_prctile25' 'IT_HF_prctile75' 'IT_HF_geomean(abs)' 'IT_HF_harmmean'\n",
            " 'IT_HF_mad' 'IT_HF_baseline' 'IT_p_Total_mean' 'IT_p_Total_std'\n",
            " 'IT_p_Total_trimmean25' 'IT_p_Total_median' 'IT_p_Total_skewness'\n",
            " 'IT_p_Total_kurtosis' 'IT_p_Total_max' 'IT_p_Total_min'\n",
            " 'IT_p_Total_prctile25' 'IT_p_Total_prctile75' 'IT_p_Total_geomean(abs)'\n",
            " 'IT_p_Total_harmmean' 'IT_p_Total_mad' 'IT_p_Total_baseline' 'IT_HF_LF'\n",
            " 'IT_LF_HF' 'IT_MF_HF' 'IT_HF_TF' 'IT_LF_MF_HF' 'IT_CCV_LF' 'IT_CCV_HF'\n",
            " 'EDA_Original_mean' 'EDA_Original_std' 'EDA_Original_trimmean25'\n",
            " 'EDA_Original_median' 'EDA_Original_skewness' 'EDA_Original_kurtosis'\n",
            " 'EDA_Original_max' 'EDA_Original_min' 'EDA_Original_prctile25'\n",
            " 'EDA_Original_prctile75' 'EDA_Original_geomean(abs)'\n",
            " 'EDA_Original_harmmean' 'EDA_Original_mad' 'EDA_Original_baseline'\n",
            " 'EDA_processed_mean' 'EDA_processed_std' 'EDA_processed_trimmean25'\n",
            " 'EDA_processed_median' 'EDA_processed_skewness' 'EDA_processed_kurtosis'\n",
            " 'EDA_processed_max' 'EDA_processed_min' 'EDA_processed_prctile25'\n",
            " 'EDA_processed_prctile75' 'EDA_processed_geomean(abs)'\n",
            " 'EDA_processed_harmmean' 'EDA_processed_mad' 'EDA_processed_baseline'\n",
            " 'EDA_Filt1_mean' 'EDA_Filt1_std' 'EDA_Filt1_trimmean25'\n",
            " 'EDA_Filt1_median' 'EDA_Filt1_skewness' 'EDA_Filt1_kurtosis'\n",
            " 'EDA_Filt1_max' 'EDA_Filt1_min' 'EDA_Filt1_prctile25'\n",
            " 'EDA_Filt1_prctile75' 'EDA_Filt1_geomean(abs)' 'EDA_Filt1_harmmean'\n",
            " 'EDA_Filt1_mad' 'EDA_Filt1_baseline' 'EDA_Filt2_mean' 'EDA_Filt2_std'\n",
            " 'EDA_Filt2_trimmean25' 'EDA_Filt2_median' 'EDA_Filt2_skewness'\n",
            " 'EDA_Filt2_kurtosis' 'EDA_Filt2_max' 'EDA_Filt2_min'\n",
            " 'EDA_Filt2_prctile25' 'EDA_Filt2_prctile75' 'EDA_Filt2_geomean(abs)'\n",
            " 'EDA_Filt2_harmmean' 'EDA_Filt2_mad' 'EDA_Filt2_baseline' 'EDA_cross_pos'\n",
            " 'EDA_cross_neg' 'EDA_n_ocu' 'EDA_amp_scr' 'EDA_p_samples' 'EDA_area'\n",
            " 'EDA_Functionals_power_Originalmean' 'EDA_Functionals_power_Originalstd'\n",
            " 'EDA_Functionals_power_Originaltrimmean25'\n",
            " 'EDA_Functionals_power_Originalmedian'\n",
            " 'EDA_Functionals_power_Originalskewness'\n",
            " 'EDA_Functionals_power_Originalkurtosis'\n",
            " 'EDA_Functionals_power_Originalmax' 'EDA_Functionals_power_Originalmin'\n",
            " 'EDA_Functionals_power_Originalprctile25'\n",
            " 'EDA_Functionals_power_Originalprctile75'\n",
            " 'EDA_Functionals_power_Originalgeomean(abs)'\n",
            " 'EDA_Functionals_power_Originalharmmean'\n",
            " 'EDA_Functionals_power_Originalmad'\n",
            " 'EDA_Functionals_power_Originalbaseline'\n",
            " 'EDA_Functionals_power_Fil12mean' 'EDA_Functionals_power_Fil12std'\n",
            " 'EDA_Functionals_power_Fil12trimmean25'\n",
            " 'EDA_Functionals_power_Fil12median' 'EDA_Functionals_power_Fil12skewness'\n",
            " 'EDA_Functionals_power_Fil12kurtosis' 'EDA_Functionals_power_Fil12max'\n",
            " 'EDA_Functionals_power_Fil12min' 'EDA_Functionals_power_Fil12prctile25'\n",
            " 'EDA_Functionals_power_Fil12prctile75'\n",
            " 'EDA_Functionals_power_Fil12geomean(abs)'\n",
            " 'EDA_Functionals_power_Fil12harmmean' 'EDA_Functionals_power_Fil12mad'\n",
            " 'EDA_Functionals_power_Fil12baseline' 'EDA_Functionals_power_Filt2mean'\n",
            " 'EDA_Functionals_power_Filt2std' 'EDA_Functionals_power_Filt2trimmean25'\n",
            " 'EDA_Functionals_power_Filt2median' 'EDA_Functionals_power_Filt2skewness'\n",
            " 'EDA_Functionals_power_Filt2kurtosis' 'EDA_Functionals_power_Filt2max'\n",
            " 'EDA_Functionals_power_Filt2min' 'EDA_Functionals_power_Filt2prctile25'\n",
            " 'EDA_Functionals_power_Filt2prctile75'\n",
            " 'EDA_Functionals_power_Filt2geomean(abs)'\n",
            " 'EDA_Functionals_power_Filt2harmmean' 'EDA_Functionals_power_Filt2mad'\n",
            " 'EDA_Functionals_power_Filt2baseline' 'EDA_Original_mean'\n",
            " 'EDA_Original_std' 'EDA_Original_trimmean25' 'EDA_Original_median'\n",
            " 'EDA_Original_skewness' 'EDA_Original_kurtosis' 'EDA_Original_max'\n",
            " 'EDA_Original_min' 'EDA_Original_prctile25' 'EDA_Original_prctile75'\n",
            " 'EDA_Original_geomean(abs)' 'EDA_Original_harmmean' 'EDA_Original_mad'\n",
            " 'EDA_Original_baseline' 'EDA_processed_mean' 'EDA_processed_std'\n",
            " 'EDA_processed_trimmean25' 'EDA_processed_median'\n",
            " 'EDA_processed_skewness' 'EDA_processed_kurtosis' 'EDA_processed_max'\n",
            " 'EDA_processed_min' 'EDA_processed_prctile25' 'EDA_processed_prctile75'\n",
            " 'EDA_processed_geomean(abs)' 'EDA_processed_harmmean' 'EDA_processed_mad'\n",
            " 'EDA_processed_baseline' 'EDA_Filt1_mean' 'EDA_Filt1_std'\n",
            " 'EDA_Filt1_trimmean25' 'EDA_Filt1_median' 'EDA_Filt1_skewness'\n",
            " 'EDA_Filt1_kurtosis' 'EDA_Filt1_max' 'EDA_Filt1_min'\n",
            " 'EDA_Filt1_prctile25' 'EDA_Filt1_prctile75' 'EDA_Filt1_geomean(abs)'\n",
            " 'EDA_Filt1_harmmean' 'EDA_Filt1_mad' 'EDA_Filt1_baseline'\n",
            " 'EDA_Filt2_mean' 'EDA_Filt2_std' 'EDA_Filt2_trimmean25'\n",
            " 'EDA_Filt2_median' 'EDA_Filt2_skewness' 'EDA_Filt2_kurtosis'\n",
            " 'EDA_Filt2_max' 'EDA_Filt2_min' 'EDA_Filt2_prctile25'\n",
            " 'EDA_Filt2_prctile75' 'EDA_Filt2_geomean(abs)' 'EDA_Filt2_harmmean'\n",
            " 'EDA_Filt2_mad' 'EDA_Filt2_baseline' 'EDA_cross_pos' 'EDA_cross_neg'\n",
            " 'EDA_n_ocu' 'EDA_amp_scr' 'EDA_p_samples' 'EDA_area'\n",
            " 'EDA_Functionals_power_Originalmean' 'EDA_Functionals_power_Originalstd'\n",
            " 'EDA_Functionals_power_Originaltrimmean25'\n",
            " 'EDA_Functionals_power_Originalmedian'\n",
            " 'EDA_Functionals_power_Originalskewness'\n",
            " 'EDA_Functionals_power_Originalkurtosis'\n",
            " 'EDA_Functionals_power_Originalmax' 'EDA_Functionals_power_Originalmin'\n",
            " 'EDA_Functionals_power_Originalprctile25'\n",
            " 'EDA_Functionals_power_Originalprctile75'\n",
            " 'EDA_Functionals_power_Originalgeomean(abs)'\n",
            " 'EDA_Functionals_power_Originalharmmean'\n",
            " 'EDA_Functionals_power_Originalmad'\n",
            " 'EDA_Functionals_power_Originalbaseline'\n",
            " 'EDA_Functionals_power_Fil12mean' 'EDA_Functionals_power_Fil12std'\n",
            " 'EDA_Functionals_power_Fil12trimmean25'\n",
            " 'EDA_Functionals_power_Fil12median' 'EDA_Functionals_power_Fil12skewness'\n",
            " 'EDA_Functionals_power_Fil12kurtosis' 'EDA_Functionals_power_Fil12max'\n",
            " 'EDA_Functionals_power_Fil12min' 'EDA_Functionals_power_Fil12prctile25'\n",
            " 'EDA_Functionals_power_Fil12prctile75'\n",
            " 'EDA_Functionals_power_Fil12geomean(abs)'\n",
            " 'EDA_Functionals_power_Fil12harmmean' 'EDA_Functionals_power_Fil12mad'\n",
            " 'EDA_Functionals_power_Fil12baseline' 'EDA_Functionals_power_Filt2mean'\n",
            " 'EDA_Functionals_power_Filt2std' 'EDA_Functionals_power_Filt2trimmean25'\n",
            " 'EDA_Functionals_power_Filt2median' 'EDA_Functionals_power_Filt2skewness'\n",
            " 'EDA_Functionals_power_Filt2kurtosis' 'EDA_Functionals_power_Filt2max'\n",
            " 'EDA_Functionals_power_Filt2min' 'EDA_Functionals_power_Filt2prctile25'\n",
            " 'EDA_Functionals_power_Filt2prctile75'\n",
            " 'EDA_Functionals_power_Filt2geomean(abs)'\n",
            " 'EDA_Functionals_power_Filt2harmmean' 'EDA_Functionals_power_Filt2mad'\n",
            " 'EDA_Functionals_power_Filt2baseline'\n",
            " 'Activity: 1-neutral, 2-emotional, 3-mental and 4-physical']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kANtSKi3aRpl"
      },
      "source": [
        "When I try to use \n",
        "\n",
        "\n",
        "```\n",
        "data = pd.read_csv('data.txt', header=None, names = feature_name)\n",
        "```\n",
        "it returns errors, and says the names are duplicated\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp1h4yj3Sz5G",
        "outputId": "a0c28084-a987-4e0b-cd11-8a0b392d904f"
      },
      "source": [
        "data = pd.read_csv('data.txt', header=None)\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4480, 535)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iZiA5RocjwL",
        "outputId": "1e3752d9-f159-4e46-c097-2c0cb6fceb0b"
      },
      "source": [
        "print(data.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.00000e+00 -4.12521e-03  2.54095e-01 ...  1.41331e+06  3.02808e+06\n",
            "   1.00000e+00]\n",
            " [ 1.00000e+00  3.10286e-02  1.93761e-01 ...  1.39018e+06  3.01642e+06\n",
            "   1.00000e+00]\n",
            " [ 1.00000e+00  1.56778e-02  1.82336e-01 ...  1.23411e+06  3.00443e+06\n",
            "   1.00000e+00]\n",
            " ...\n",
            " [ 4.00000e+01  2.46725e-02  2.13325e-01 ...  6.01107e+06  4.25422e+05\n",
            "   4.00000e+00]\n",
            " [ 4.00000e+01  2.50627e-02  2.12210e-01 ...  6.54401e+06  4.39695e+05\n",
            "   4.00000e+00]\n",
            " [ 4.00000e+01  2.55506e-03  2.32580e-01 ...  6.72173e+06  4.54341e+05\n",
            "   4.00000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSmxfcfhO-rp",
        "outputId": "4b635518-0169-4496-9809-ee1676fdb335"
      },
      "source": [
        "data_arr = data.values\n",
        "X = data_arr[:, 1:-1]\n",
        "y = data_arr[:,-1]\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4480, 533) (4480,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxxZ0TMKZitW",
        "outputId": "4fbf2386-1199-4d0a-f203-b3bf360085ec"
      },
      "source": [
        "# split data into train and test dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y, shuffle=True)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3360, 533) (1120, 533)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmY1MWC1dLiI"
      },
      "source": [
        "Too many features, it's necessary to use some methods to reduce the dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5E98nhDARh1"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxFrWQM7AyOs"
      },
      "source": [
        "## Scale data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2gRnij_dSwf"
      },
      "source": [
        "For some methods, it's necessary to scale the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2WsoR2SA002"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scale = scaler.transform(X_train)\n",
        "X_test_scale = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE3BuhobA3ak"
      },
      "source": [
        "## Feature selections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOxSGsW1Ag3F"
      },
      "source": [
        "If we use some traditional ML methods, it's important to reduce the dimension by removing most nuisance variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A-M_IodAkl1"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vgTIikDEhZX"
      },
      "source": [
        "The simplest way is to apply PCA to select features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqXkkiz6_JRl",
        "outputId": "bbe7a83a-2438-4e09-d7f0-ddba1a2badf9"
      },
      "source": [
        "pca = PCA(n_components=100,svd_solver='randomized', whiten=True)\n",
        "pca.fit(X_train_scale)\n",
        "\n",
        "X_train_pca = pca.transform(X_train_scale)\n",
        "X_test_pca = pca.transform(X_test_scale)\n",
        "print(np.sum(pca.explained_variance_ratio_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9894863674773985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2qe6BkNFLxf"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1NEN5MVF3av"
      },
      "source": [
        "We can also use RF to select important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvxJB8UI_Lve",
        "outputId": "12857503-1397-4783-8d06-072944c2a419"
      },
      "source": [
        "n_component = 200\n",
        "\n",
        "model = RandomForestClassifier(n_jobs=8, random_state=0)\n",
        "model.fit(X_train_scale, y_train.ravel())\n",
        "\n",
        "feature_importance = model.feature_importances_\n",
        "\n",
        "index = np.argsort(feature_importance)[-1:-n_component-1:-1]\n",
        "\n",
        "X_train_RF = X_train_scale[:, index]\n",
        "X_test_RF = X_test_scale[:, index]\n",
        "\n",
        "print(np.sum(feature_importance[index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8004458696669909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_RdhPHwdqxv",
        "outputId": "7daaa108-c2c0-4a26-909b-16fbdca9b82a"
      },
      "source": [
        "print(feature_name[index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['IT_LF_harmmean' 'IT_Original_harmmean' 'ECG_hrv_std' 'ECG_hrv_min'\n",
            " 'ECG_hrv_prctile25' 'ECG_HR_min_div_std' 'ECG_hrv_prctile75'\n",
            " 'ECG_Entropyaprox' 'ECG_HR_min_div_trimmean25' 'ECG_RSAindex'\n",
            " 'ECG_hrv_trimmean25' 'IT_Original_mean' 'IT_LF_kurtosis' 'IT_BRV_mad'\n",
            " 'ECG_RR_window_prctile75' 'IT_LF_trimmean25' 'ECG_hrv_kurtosis'\n",
            " 'IT_LF_mean' 'ECG_amplitude_RR_baseline' 'ECG_original_baseline'\n",
            " 'IT_PSD_mad' 'IT_RF_harmmean' 'ECG_HR_min_div_min' 'EDA_processed_mad'\n",
            " 'ECG_RR_window_trimmean25' 'IT_Original_kurtosis' 'IT_LF_prctile75'\n",
            " 'IT_LF_mad' 'IT_VLF_prctile75' 'IT_VLF_baseline' 'IT_HF_mad' 'IT_MF_mad'\n",
            " 'IT_MF_geomean(abs)' 'IT_LF_mad' 'IT_BRV_mean' 'IT_VLF_mad' 'IT_RF_mad'\n",
            " 'IT_BRV_std' 'IT_p_Total_harmmean' 'IT_MF_prctile75' 'IT_VLF_std'\n",
            " 'IT_Original_mad' 'IT_VLF_trimmean25' 'IT_LF_mean' 'IT_p_Total_mad'\n",
            " 'IT_p_Total_kurtosis' 'IT_RF_prctile25' 'ECG_RR_window_prctile25'\n",
            " 'ECG_RR_window_max' 'IT_RF_prctile75' 'IT_p_Total_geomean(abs)'\n",
            " 'IT_PSD_baseline' 'IT_p_Total_mean' 'ECG_HR_min_div_prctile25'\n",
            " 'IT_LF_MF_HF' 'IT_VLF_kurtosis' 'IT_LF_baseline' 'IT_LF_min'\n",
            " 'IT_VLF_prctile25' 'ECG_HR_min_div_prctile75' 'IT_BRV_geomean(abs)'\n",
            " 'IT_CCV_LF' 'IT_MF_mean' 'IT_LF_prctile25' 'IT_MF_trimmean25'\n",
            " 'IT_VLF_min' 'IT_MF_harmmean' 'EDA_processed_prctile25'\n",
            " 'EDA_processed_mad' 'IT_MF_std' 'ECG_A2_DFA' 'ECG_RR_window_geomean(abs)'\n",
            " 'IT_BRV_skewness' 'IT_LF_geomean(abs)' 'ECG_HR_min_div_geomean(abs)'\n",
            " 'IT_HF_baseline' 'ECG_original_mean' 'ECG_hrv_max' 'IT_MF_kurtosis'\n",
            " 'IT_BR_mean' 'IT_BRV_prctile25' 'IT_p_Total_prctile75'\n",
            " 'IT_BRV_trimmean25' 'IT_BRV_min' 'IT_BRV_kurtosis' 'IT_BRV_max'\n",
            " 'ECG_original_mad' 'ECG_p_MF_mad' 'IT_RF_kurtosis'\n",
            " 'ECG_amplitude_RR_kurtosis' 'ECG_original_prctile25' 'ECG_RR_window_std'\n",
            " 'ECG_HR_min_div_kurtosis' 'ECG_p_total_LF_mad' 'IT_RF_mean' 'ECG_hrv_mad'\n",
            " 'ECG_original_kurtosis' 'ECG_original_prctile75' 'ECG_hrv_geomean(abs)'\n",
            " 'ECG_HR_min_div_mad' 'ECG_amplitude_RR_max' 'ECG_RR_window_min'\n",
            " 'ECG_amplitude_RR_mad' 'IT_LF_prctile25' 'IT_LF_std' 'IT_VLF_max'\n",
            " 'ECG_RR_window_median' 'IT_Original_prctile75' 'IT_RF_Area'\n",
            " 'ECG_p_LF_mad' 'IT_Original_max' 'EDA_Filt1_min' 'IT_Original_min'\n",
            " 'IT_p_Total_std' 'EDA_Original_geomean(abs)' 'EDA_Filt2_mad' 'IT_MF_min'\n",
            " 'IT_Original_prctile25' 'IT_VLF_mean' 'IT_PSD_harmmean' 'EDA_Filt2_mad'\n",
            " 'EDA_Functionals_power_Fil12mad' 'ECG_original_median' 'IT_PSD_mean'\n",
            " 'IT_PSD_min' 'IT_p_Total_min' 'IT_p_Total_max'\n",
            " 'EDA_Functionals_power_Originalmad' 'IT_VLF_geomean(abs)'\n",
            " 'ECG_amplitude_RR_min' 'IT_MF_baseline' 'EDA_Filt1_mad' 'ECG_PSD_mad'\n",
            " 'EDA_Functionals_power_Fil12mad' 'ECG_HR_min_div_max' 'IT_VLF_harmmean'\n",
            " 'IT_PSD_kurtosis' 'IT_LF_min' 'ECG_p_HF_mad' 'EDA_Original_mad'\n",
            " 'ECG_RR_window_mad' 'IT_LF_kurtosis' 'ECG_PSD_trimmean25' 'ECG_p_VFL_mad'\n",
            " 'IT_LF_harmmean' 'ECG_NN50' 'IT_LF_trimmean25' 'ECG_original_min'\n",
            " 'IT_LF_max' 'IT_RF_min' 'EDA_Original_mad' 'IT_HF_prctile25'\n",
            " 'ECG_amplitude_RR_mean' 'ECG_original_skewness' 'IT_BRV_baseline'\n",
            " 'ECG_amplitude_RR_prctile25' 'ECG_RR_window_mean' 'EDA_Filt1_max'\n",
            " 'IT_LF_geomean(abs)' 'IT_Original_trimmean25' 'EDA_processed_min'\n",
            " 'IT_Original_std' 'ECG_M' 'EDA_Functionals_power_Originalmad'\n",
            " 'EDA_Filt2_trimmean25' 'EDA_Functionals_power_Originaltrimmean25'\n",
            " 'IT_Original_Area' 'EDA_Functionals_power_Originalprctile75'\n",
            " 'ECG_original_max' 'IT_LF_Area' 'EDA_Functionals_power_Filt2prctile75'\n",
            " 'ECG_amplitude_RR_std' 'IT_LF_prctile75' 'EDA_Functionals_power_Filt2mad'\n",
            " 'EDA_Filt1_prctile75' 'IT_p_Total_skewness' 'EDA_Filt2_kurtosis'\n",
            " 'ECG_original_harmmean' 'IT_RF_trimmean25' 'IT_Original_baseline'\n",
            " 'IT_RF_skewness' 'IT_RF_std' 'EDA_Filt1_prctile25' 'EDA_Filt2_max'\n",
            " 'EDA_Functionals_power_Filt2mad' 'IT_RF_max'\n",
            " 'ECG_amplitude_RR_trimmean25' 'EDA_Filt2_std' 'EDA_processed_kurtosis'\n",
            " 'ECG_amplitude_RR_prctile75' 'EDA_Original_std'\n",
            " 'IT_Original_geomean(abs)' 'EDA_Filt2_trimmean25'\n",
            " 'EDA_Functionals_power_Originaltrimmean25'\n",
            " 'EDA_Functionals_power_Fil12std' 'EDA_Functionals_power_Filt2baseline'\n",
            " 'ECG_RR_window_kurtosis' 'EDA_Filt2_min' 'IT_BRV_prctile75'\n",
            " 'EDA_Functionals_power_Filt2prctile75']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIMz_0fuGnZn"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtJEIj0UHEKX"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqUn1eFqGiGm"
      },
      "source": [
        "p_grid_lsvm = {'C': [1e-3,1e-2,0.05,1e-1,0.5,1,2,5,1e1,1e2,15,20,40,60,80,120,140],\n",
        "                'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 1,2,4,8,10,15,20,30,40,50,60], }\n",
        "Lsvm = SVC(kernel='rbf')\n",
        "grid_lsvm = GridSearchCV(estimator=Lsvm, param_grid=p_grid_lsvm, scoring='f1_macro', cv=5, n_jobs=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31h1wrwtH7JX"
      },
      "source": [
        "### PCA preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMObSEI-H6CH",
        "outputId": "3204309c-e737-4b1f-aedb-6aa04a5ce47f"
      },
      "source": [
        "grid_lsvm.fit(X_train_pca, y_train.ravel())\n",
        "test_score = grid_lsvm.score(X_test_pca, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_lsvm.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_lsvm.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best training Score: 0.9218288217136322\n",
            "Best training params: {'C': 100.0, 'gamma': 0.005}\n",
            "Test score: 0.9173992595782752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0wfH46xIGFB"
      },
      "source": [
        "### RF preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prs6W0qeI1AZ",
        "outputId": "b47cb0ff-7d76-4f67-c85b-53524d1307f3"
      },
      "source": [
        "grid_lsvm.fit(X_train_RF, y_train.ravel())\n",
        "test_score = grid_lsvm.score(X_test_RF, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_lsvm.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_lsvm.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best training Score: 0.9573292439132775\n",
            "Best training params: {'C': 140, 'gamma': 0.01}\n",
            "Test score: 0.9580402509506486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JpYuIdo0gQb"
      },
      "source": [
        "### Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOyR0Yqs0jgI"
      },
      "source": [
        "The results of SVM seem very good, can achieve 0.958 f1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uFkBJmpHPD9"
      },
      "source": [
        "## Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9sPVXZHHDEN"
      },
      "source": [
        "XGB = XGBClassifier()\n",
        "p_grid_xgb = dict(\n",
        "    max_depth = [4, 5, 6, 7],\n",
        "    learning_rate = np.linspace(0.03, 0.3, 10),\n",
        "    n_estimators = [100, 200]\n",
        ")\n",
        "\n",
        "grid_xgb = GridSearchCV(estimator=XGB, param_grid=p_grid_xgb, scoring='f1_macro', cv=5, n_jobs = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg-ZKgtYJX-T"
      },
      "source": [
        "### PCA preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbj6CiAgJX-T",
        "outputId": "f009d050-266d-4d01-d74d-e517c668ae25"
      },
      "source": [
        "grid_xgb.fit(X_train_pca, y_train.ravel())\n",
        "test_score = grid_xgb.score(X_test_pca, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_xgb.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_xgb.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best training Score: 0.9047633318624646\n",
            "Best training params: {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 200}\n",
            "Test score: 0.9138744485163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0ZMjA9vJX-U"
      },
      "source": [
        "### RF preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJeL52MoJX-U",
        "outputId": "032338e8-e0cb-4d27-f93f-a1b699051640"
      },
      "source": [
        "grid_xgb.fit(X_train_RF, y_train.ravel())\n",
        "test_score = grid_xgb.score(X_test_RF, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_xgb.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_xgb.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best training Score: 0.9958358824385221\n",
            "Best training params: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 200}\n",
            "Test score: 0.9982126770551818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRBOm6jz0yj3"
      },
      "source": [
        "### Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAWsGlJX00ox"
      },
      "source": [
        "Amazing!!!\n",
        "\n",
        "The best f1 score is 0.998 for boosting method, which is much better than SVM. Maybe this time, the candidate hyperparameter list is suitable, and then we can achieve a rather good result. From this result, we can find the advantage of ensemble method is that if we can find a good hyperparameter, the score will be close to 1\n",
        "\n",
        "The disadvantage is that it's too slow, I run about 1.5 hours for one cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCF1e6LnHFlv"
      },
      "source": [
        "## MLP from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jOOWMFgpJnQI"
      },
      "source": [
        "MLP = MLPClassifier(activation='relu', alpha=1e-4, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(256,256,128), \n",
        "       learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
        "       tol=0.0001, validation_fraction=0.1,\n",
        "       warm_start=False, verbose=10)\n",
        "\n",
        "p_grid_mlp = {'solver': ['adam', 'sgd'], 'learning_rate' : ['adaptive', 'constant']}\n",
        "grid_mlp = GridSearchCV(estimator=MLP, param_grid=p_grid_mlp, scoring='f1_macro', cv=5, n_jobs = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU7LpNxPWA37"
      },
      "source": [
        "### Original dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "leijssE3WJej",
        "outputId": "f62cc12f-7034-4337-d78d-660b6be96512"
      },
      "source": [
        "grid_mlp.fit(X_train_scale, y_train.ravel())\n",
        "test_score = grid_mlp.score(X_test_scale, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_mlp.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_mlp.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.06711698\n",
            "Iteration 2, loss = 0.59322218\n",
            "Iteration 3, loss = 0.46943327\n",
            "Iteration 4, loss = 0.40232163\n",
            "Iteration 5, loss = 0.35621447\n",
            "Iteration 6, loss = 0.31909582\n",
            "Iteration 7, loss = 0.28996054\n",
            "Iteration 8, loss = 0.25657780\n",
            "Iteration 9, loss = 0.23495806\n",
            "Iteration 10, loss = 0.21514567\n",
            "Iteration 11, loss = 0.19332719\n",
            "Iteration 12, loss = 0.17792871\n",
            "Iteration 13, loss = 0.16293230\n",
            "Iteration 14, loss = 0.15295348\n",
            "Iteration 15, loss = 0.13975993\n",
            "Iteration 16, loss = 0.13240095\n",
            "Iteration 17, loss = 0.11866870\n",
            "Iteration 18, loss = 0.11330361\n",
            "Iteration 19, loss = 0.10457455\n",
            "Iteration 20, loss = 0.09695808\n",
            "Iteration 21, loss = 0.09003100\n",
            "Iteration 22, loss = 0.08407912\n",
            "Iteration 23, loss = 0.07867041\n",
            "Iteration 24, loss = 0.08135036\n",
            "Iteration 25, loss = 0.07039680\n",
            "Iteration 26, loss = 0.07057068\n",
            "Iteration 27, loss = 0.06347902\n",
            "Iteration 28, loss = 0.05986975\n",
            "Iteration 29, loss = 0.05586489\n",
            "Iteration 30, loss = 0.05069077\n",
            "Iteration 31, loss = 0.05151259\n",
            "Iteration 32, loss = 0.04438776\n",
            "Iteration 33, loss = 0.04479655\n",
            "Iteration 34, loss = 0.03909331\n",
            "Iteration 35, loss = 0.03713583\n",
            "Iteration 36, loss = 0.03812943\n",
            "Iteration 37, loss = 0.03792927\n",
            "Iteration 38, loss = 0.03280252\n",
            "Iteration 39, loss = 0.02908655\n",
            "Iteration 40, loss = 0.02526872\n",
            "Iteration 41, loss = 0.02960074\n",
            "Iteration 42, loss = 0.02462607\n",
            "Iteration 43, loss = 0.02336986\n",
            "Iteration 44, loss = 0.02420259\n",
            "Iteration 45, loss = 0.02914574\n",
            "Iteration 46, loss = 0.02300754\n",
            "Iteration 47, loss = 0.02378312\n",
            "Iteration 48, loss = 0.02106700\n",
            "Iteration 49, loss = 0.01860120\n",
            "Iteration 50, loss = 0.03409519\n",
            "Iteration 51, loss = 0.03456618\n",
            "Iteration 52, loss = 0.02252413\n",
            "Iteration 53, loss = 0.01455609\n",
            "Iteration 54, loss = 0.01383094\n",
            "Iteration 55, loss = 0.03561229\n",
            "Iteration 56, loss = 0.01562482\n",
            "Iteration 57, loss = 0.01484865\n",
            "Iteration 58, loss = 0.01069264\n",
            "Iteration 59, loss = 0.01311952\n",
            "Iteration 60, loss = 0.00908149\n",
            "Iteration 61, loss = 0.00809315\n",
            "Iteration 62, loss = 0.00733254\n",
            "Iteration 63, loss = 0.00739286\n",
            "Iteration 64, loss = 0.00686081\n",
            "Iteration 65, loss = 0.00625630\n",
            "Iteration 66, loss = 0.00591625\n",
            "Iteration 67, loss = 0.00580214\n",
            "Iteration 68, loss = 0.00536168\n",
            "Iteration 69, loss = 0.00535124\n",
            "Iteration 70, loss = 0.00577621\n",
            "Iteration 71, loss = 0.00606292\n",
            "Iteration 72, loss = 0.00494063\n",
            "Iteration 73, loss = 0.00494954\n",
            "Iteration 74, loss = 0.00447426\n",
            "Iteration 75, loss = 0.00426043\n",
            "Iteration 76, loss = 0.00392387\n",
            "Iteration 77, loss = 0.00416065\n",
            "Iteration 78, loss = 0.00423400\n",
            "Iteration 79, loss = 0.00358325\n",
            "Iteration 80, loss = 0.00356518\n",
            "Iteration 81, loss = 0.00341927\n",
            "Iteration 82, loss = 0.00320350\n",
            "Iteration 83, loss = 0.00305563\n",
            "Iteration 84, loss = 0.00311254\n",
            "Iteration 85, loss = 0.00315862\n",
            "Iteration 86, loss = 0.00285337\n",
            "Iteration 87, loss = 0.00295053\n",
            "Iteration 88, loss = 0.00297664\n",
            "Iteration 89, loss = 0.00264887\n",
            "Iteration 90, loss = 0.00261685\n",
            "Iteration 91, loss = 0.00255969\n",
            "Iteration 92, loss = 0.00242856\n",
            "Iteration 93, loss = 0.00251312\n",
            "Iteration 94, loss = 0.00238901\n",
            "Iteration 95, loss = 0.00237267\n",
            "Iteration 96, loss = 0.00237298\n",
            "Iteration 97, loss = 0.00222601\n",
            "Iteration 98, loss = 0.00231277\n",
            "Iteration 99, loss = 0.00223912\n",
            "Iteration 100, loss = 0.00208321\n",
            "Iteration 101, loss = 0.00210517\n",
            "Iteration 102, loss = 0.00235234\n",
            "Iteration 103, loss = 0.00208826\n",
            "Iteration 104, loss = 0.00219246\n",
            "Iteration 105, loss = 0.00198560\n",
            "Iteration 106, loss = 0.00210513\n",
            "Iteration 107, loss = 0.00189992\n",
            "Iteration 108, loss = 0.00189491\n",
            "Iteration 109, loss = 0.00183520\n",
            "Iteration 110, loss = 0.00176294\n",
            "Iteration 111, loss = 0.00172183\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.002000\n",
            "Iteration 112, loss = 0.00172945\n",
            "Iteration 113, loss = 0.00164713\n",
            "Iteration 114, loss = 0.00162747\n",
            "Iteration 115, loss = 0.00159728\n",
            "Iteration 116, loss = 0.00158699\n",
            "Iteration 117, loss = 0.00157891\n",
            "Iteration 118, loss = 0.00157553\n",
            "Iteration 119, loss = 0.00157009\n",
            "Iteration 120, loss = 0.00156600\n",
            "Iteration 121, loss = 0.00156230\n",
            "Iteration 122, loss = 0.00155239\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000400\n",
            "Iteration 123, loss = 0.00154322\n",
            "Iteration 124, loss = 0.00153929\n",
            "Iteration 125, loss = 0.00153668\n",
            "Iteration 126, loss = 0.00153608\n",
            "Iteration 127, loss = 0.00153473\n",
            "Iteration 128, loss = 0.00153285\n",
            "Iteration 129, loss = 0.00153273\n",
            "Iteration 130, loss = 0.00153060\n",
            "Iteration 131, loss = 0.00153067\n",
            "Iteration 132, loss = 0.00152931\n",
            "Iteration 133, loss = 0.00152932\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000080\n",
            "Iteration 134, loss = 0.00152502\n",
            "Iteration 135, loss = 0.00152532\n",
            "Iteration 136, loss = 0.00152458\n",
            "Iteration 137, loss = 0.00152456\n",
            "Iteration 138, loss = 0.00152430\n",
            "Iteration 139, loss = 0.00152394\n",
            "Iteration 140, loss = 0.00152397\n",
            "Iteration 141, loss = 0.00152366\n",
            "Iteration 142, loss = 0.00152339\n",
            "Iteration 143, loss = 0.00152336\n",
            "Iteration 144, loss = 0.00152351\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000016\n",
            "Iteration 145, loss = 0.00152249\n",
            "Iteration 146, loss = 0.00152236\n",
            "Iteration 147, loss = 0.00152227\n",
            "Iteration 148, loss = 0.00152229\n",
            "Iteration 149, loss = 0.00152221\n",
            "Iteration 150, loss = 0.00152217\n",
            "Iteration 151, loss = 0.00152217\n",
            "Iteration 152, loss = 0.00152212\n",
            "Iteration 153, loss = 0.00152215\n",
            "Iteration 154, loss = 0.00152205\n",
            "Iteration 155, loss = 0.00152205\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000003\n",
            "Iteration 156, loss = 0.00152188\n",
            "Iteration 157, loss = 0.00152188\n",
            "Iteration 158, loss = 0.00152187\n",
            "Iteration 159, loss = 0.00152186\n",
            "Iteration 160, loss = 0.00152186\n",
            "Iteration 161, loss = 0.00152185\n",
            "Iteration 162, loss = 0.00152184\n",
            "Iteration 163, loss = 0.00152186\n",
            "Iteration 164, loss = 0.00152184\n",
            "Iteration 165, loss = 0.00152182\n",
            "Iteration 166, loss = 0.00152181\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000001\n",
            "Iteration 167, loss = 0.00152179\n",
            "Iteration 168, loss = 0.00152179\n",
            "Iteration 169, loss = 0.00152178\n",
            "Iteration 170, loss = 0.00152178\n",
            "Iteration 171, loss = 0.00152178\n",
            "Iteration 172, loss = 0.00152178\n",
            "Iteration 173, loss = 0.00152178\n",
            "Iteration 174, loss = 0.00152178\n",
            "Iteration 175, loss = 0.00152178\n",
            "Iteration 176, loss = 0.00152178\n",
            "Iteration 177, loss = 0.00152178\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Best training Score: 0.9383975700300626\n",
            "Best training params: {'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "Test score: 0.9454282000084379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMm9BFtNJ20a"
      },
      "source": [
        "### PCA preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-5zlC_w6J20b"
      },
      "source": [
        "grid_mlp.fit(X_train_pca, y_train.ravel())\n",
        "test_score = grid_mlp.score(X_test_pca, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_mlp.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_mlp.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vopQQ_vxJ20b"
      },
      "source": [
        "### RF preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekf5CwfKJ20b",
        "outputId": "dfbb4a0b-d5d8-4aac-f15a-03f7318a0c52"
      },
      "source": [
        "grid_mlp.fit(X_train_RF, y_train.ravel())\n",
        "test_score = grid_mlp.score(X_test_RF, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_mlp.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_mlp.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.04985960\n",
            "Iteration 2, loss = 0.63727822\n",
            "Iteration 3, loss = 0.52461790\n",
            "Iteration 4, loss = 0.46089517\n",
            "Iteration 5, loss = 0.41608143\n",
            "Iteration 6, loss = 0.38129003\n",
            "Iteration 7, loss = 0.35117329\n",
            "Iteration 8, loss = 0.32573186\n",
            "Iteration 9, loss = 0.30401093\n",
            "Iteration 10, loss = 0.28400534\n",
            "Iteration 11, loss = 0.26503061\n",
            "Iteration 12, loss = 0.24958962\n",
            "Iteration 13, loss = 0.23437216\n",
            "Iteration 14, loss = 0.22313299\n",
            "Iteration 15, loss = 0.20990740\n",
            "Iteration 16, loss = 0.19822792\n",
            "Iteration 17, loss = 0.19004263\n",
            "Iteration 18, loss = 0.18048738\n",
            "Iteration 19, loss = 0.17183089\n",
            "Iteration 20, loss = 0.16583936\n",
            "Iteration 21, loss = 0.15574333\n",
            "Iteration 22, loss = 0.14756419\n",
            "Iteration 23, loss = 0.14385961\n",
            "Iteration 24, loss = 0.14065025\n",
            "Iteration 25, loss = 0.13246616\n",
            "Iteration 26, loss = 0.12535566\n",
            "Iteration 27, loss = 0.12591611\n",
            "Iteration 28, loss = 0.11796254\n",
            "Iteration 29, loss = 0.11312187\n",
            "Iteration 30, loss = 0.11272455\n",
            "Iteration 31, loss = 0.10220925\n",
            "Iteration 32, loss = 0.10530458\n",
            "Iteration 33, loss = 0.10082497\n",
            "Iteration 34, loss = 0.09576488\n",
            "Iteration 35, loss = 0.09441896\n",
            "Iteration 36, loss = 0.08974022\n",
            "Iteration 37, loss = 0.08661590\n",
            "Iteration 38, loss = 0.08237900\n",
            "Iteration 39, loss = 0.07961367\n",
            "Iteration 40, loss = 0.08662354\n",
            "Iteration 41, loss = 0.07180619\n",
            "Iteration 42, loss = 0.06969641\n",
            "Iteration 43, loss = 0.07550156\n",
            "Iteration 44, loss = 0.06400095\n",
            "Iteration 45, loss = 0.08224698\n",
            "Iteration 46, loss = 0.06639184\n",
            "Iteration 47, loss = 0.07876531\n",
            "Iteration 48, loss = 0.06809421\n",
            "Iteration 49, loss = 0.09209096\n",
            "Iteration 50, loss = 0.06636710\n",
            "Iteration 51, loss = 0.06455566\n",
            "Iteration 52, loss = 0.10634593\n",
            "Iteration 53, loss = 0.06528416\n",
            "Iteration 54, loss = 0.05461722\n",
            "Iteration 55, loss = 0.06415572\n",
            "Iteration 56, loss = 0.05556971\n",
            "Iteration 57, loss = 0.04721091\n",
            "Iteration 58, loss = 0.05726899\n",
            "Iteration 59, loss = 0.04834974\n",
            "Iteration 60, loss = 0.04800906\n",
            "Iteration 61, loss = 0.04623673\n",
            "Iteration 62, loss = 0.04439907\n",
            "Iteration 63, loss = 0.03855572\n",
            "Iteration 64, loss = 0.03808896\n",
            "Iteration 65, loss = 0.03674766\n",
            "Iteration 66, loss = 0.03940329\n",
            "Iteration 67, loss = 0.05734635\n",
            "Iteration 68, loss = 0.03394130\n",
            "Iteration 69, loss = 0.06470655\n",
            "Iteration 70, loss = 0.04078830\n",
            "Iteration 71, loss = 0.03783118\n",
            "Iteration 72, loss = 0.04081916\n",
            "Iteration 73, loss = 0.03866935\n",
            "Iteration 74, loss = 0.03766093\n",
            "Iteration 75, loss = 0.05048448\n",
            "Iteration 76, loss = 0.05662497\n",
            "Iteration 77, loss = 0.03459062\n",
            "Iteration 78, loss = 0.03445732\n",
            "Iteration 79, loss = 0.03259068\n",
            "Iteration 80, loss = 0.03374443\n",
            "Iteration 81, loss = 0.02773208\n",
            "Iteration 82, loss = 0.02857187\n",
            "Iteration 83, loss = 0.02586230\n",
            "Iteration 84, loss = 0.03846057\n",
            "Iteration 85, loss = 0.03635995\n",
            "Iteration 86, loss = 0.02496699\n",
            "Iteration 87, loss = 0.02595793\n",
            "Iteration 88, loss = 0.02747415\n",
            "Iteration 89, loss = 0.02277432\n",
            "Iteration 90, loss = 0.02953864\n",
            "Iteration 91, loss = 0.02239496\n",
            "Iteration 92, loss = 0.01932347\n",
            "Iteration 93, loss = 0.02418278\n",
            "Iteration 94, loss = 0.03203466\n",
            "Iteration 95, loss = 0.02933742\n",
            "Iteration 96, loss = 0.02942547\n",
            "Iteration 97, loss = 0.01987927\n",
            "Iteration 98, loss = 0.03204907\n",
            "Iteration 99, loss = 0.02768336\n",
            "Iteration 100, loss = 0.02264189\n",
            "Iteration 101, loss = 0.01725174\n",
            "Iteration 102, loss = 0.02102340\n",
            "Iteration 103, loss = 0.03436560\n",
            "Iteration 104, loss = 0.02061754\n",
            "Iteration 105, loss = 0.02473991\n",
            "Iteration 106, loss = 0.02996127\n",
            "Iteration 107, loss = 0.02211484\n",
            "Iteration 108, loss = 0.01680758\n",
            "Iteration 109, loss = 0.01503978\n",
            "Iteration 110, loss = 0.01299422\n",
            "Iteration 111, loss = 0.01253905\n",
            "Iteration 112, loss = 0.01410843\n",
            "Iteration 113, loss = 0.01354988\n",
            "Iteration 114, loss = 0.01236574\n",
            "Iteration 115, loss = 0.01329166\n",
            "Iteration 116, loss = 0.01059269\n",
            "Iteration 117, loss = 0.01250104\n",
            "Iteration 118, loss = 0.02674633\n",
            "Iteration 119, loss = 0.01470309\n",
            "Iteration 120, loss = 0.01234990\n",
            "Iteration 121, loss = 0.00969755\n",
            "Iteration 122, loss = 0.00889024\n",
            "Iteration 123, loss = 0.00867680\n",
            "Iteration 124, loss = 0.00854029\n",
            "Iteration 125, loss = 0.00811020\n",
            "Iteration 126, loss = 0.00830799\n",
            "Iteration 127, loss = 0.00792462\n",
            "Iteration 128, loss = 0.01045919\n",
            "Iteration 129, loss = 0.00896623\n",
            "Iteration 130, loss = 0.00757204\n",
            "Iteration 131, loss = 0.00863802\n",
            "Iteration 132, loss = 0.00740910\n",
            "Iteration 133, loss = 0.00834685\n",
            "Iteration 134, loss = 0.00639461\n",
            "Iteration 135, loss = 0.00818764\n",
            "Iteration 136, loss = 0.00863639\n",
            "Iteration 137, loss = 0.03167532\n",
            "Iteration 138, loss = 0.02155822\n",
            "Iteration 139, loss = 0.01304995\n",
            "Iteration 140, loss = 0.00949632\n",
            "Iteration 141, loss = 0.02338600\n",
            "Iteration 142, loss = 0.01151055\n",
            "Iteration 143, loss = 0.01815796\n",
            "Iteration 144, loss = 0.01702360\n",
            "Iteration 145, loss = 0.04436415\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.002000\n",
            "Iteration 146, loss = 0.01288475\n",
            "Iteration 147, loss = 0.00978897\n",
            "Iteration 148, loss = 0.00824784\n",
            "Iteration 149, loss = 0.00659875\n",
            "Iteration 150, loss = 0.00561309\n",
            "Iteration 151, loss = 0.00549298\n",
            "Iteration 152, loss = 0.00534911\n",
            "Iteration 153, loss = 0.00520034\n",
            "Iteration 154, loss = 0.00525771\n",
            "Iteration 155, loss = 0.00495574\n",
            "Iteration 156, loss = 0.00499336\n",
            "Iteration 157, loss = 0.00509905\n",
            "Iteration 158, loss = 0.00487961\n",
            "Iteration 159, loss = 0.00484657\n",
            "Iteration 160, loss = 0.00509297\n",
            "Iteration 161, loss = 0.00482378\n",
            "Iteration 162, loss = 0.00476659\n",
            "Iteration 163, loss = 0.00470470\n",
            "Iteration 164, loss = 0.00477637\n",
            "Iteration 165, loss = 0.00461751\n",
            "Iteration 166, loss = 0.00464975\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000400\n",
            "Iteration 167, loss = 0.00446391\n",
            "Iteration 168, loss = 0.00439656\n",
            "Iteration 169, loss = 0.00437418\n",
            "Iteration 170, loss = 0.00437234\n",
            "Iteration 171, loss = 0.00434607\n",
            "Iteration 172, loss = 0.00433548\n",
            "Iteration 173, loss = 0.00432268\n",
            "Iteration 174, loss = 0.00435561\n",
            "Iteration 175, loss = 0.00431328\n",
            "Iteration 176, loss = 0.00430771\n",
            "Iteration 177, loss = 0.00431301\n",
            "Iteration 178, loss = 0.00429475\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000080\n",
            "Iteration 179, loss = 0.00430849\n",
            "Iteration 180, loss = 0.00427223\n",
            "Iteration 181, loss = 0.00425925\n",
            "Iteration 182, loss = 0.00426073\n",
            "Iteration 183, loss = 0.00426177\n",
            "Iteration 184, loss = 0.00425599\n",
            "Iteration 185, loss = 0.00425611\n",
            "Iteration 186, loss = 0.00426228\n",
            "Iteration 187, loss = 0.00425316\n",
            "Iteration 188, loss = 0.00425264\n",
            "Iteration 189, loss = 0.00425188\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000016\n",
            "Iteration 190, loss = 0.00424459\n",
            "Iteration 191, loss = 0.00424466\n",
            "Iteration 192, loss = 0.00424412\n",
            "Iteration 193, loss = 0.00424402\n",
            "Iteration 194, loss = 0.00424282\n",
            "Iteration 195, loss = 0.00424485\n",
            "Iteration 196, loss = 0.00424294\n",
            "Iteration 197, loss = 0.00424295\n",
            "Iteration 198, loss = 0.00424246\n",
            "Iteration 199, loss = 0.00424312\n",
            "Iteration 200, loss = 0.00424322\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000003\n",
            "Iteration 201, loss = 0.00424074\n",
            "Iteration 202, loss = 0.00424098\n",
            "Iteration 203, loss = 0.00424070\n",
            "Iteration 204, loss = 0.00424085\n",
            "Iteration 205, loss = 0.00424080\n",
            "Iteration 206, loss = 0.00424095\n",
            "Iteration 207, loss = 0.00424085\n",
            "Iteration 208, loss = 0.00424111\n",
            "Iteration 209, loss = 0.00424042\n",
            "Iteration 210, loss = 0.00424060\n",
            "Iteration 211, loss = 0.00424062\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000001\n",
            "Iteration 212, loss = 0.00424021\n",
            "Iteration 213, loss = 0.00424020\n",
            "Iteration 214, loss = 0.00424024\n",
            "Iteration 215, loss = 0.00424020\n",
            "Iteration 216, loss = 0.00424020\n",
            "Iteration 217, loss = 0.00424014\n",
            "Iteration 218, loss = 0.00424014\n",
            "Iteration 219, loss = 0.00424028\n",
            "Iteration 220, loss = 0.00424012\n",
            "Iteration 221, loss = 0.00424016\n",
            "Iteration 222, loss = 0.00424019\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Best training Score: 0.970596396472849\n",
            "Best training params: {'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "Test score: 0.9697355878495814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emUXJBCg1-sb"
      },
      "source": [
        "### Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hxnP5Yu2D03"
      },
      "source": [
        "This time, RF preprocessed data can have a better performance. I think one possible reason is that the original data has too many nuisance variables, which reduce the performance, but if we use RF to select the features, we can avoid this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wix_NHmYZT-"
      },
      "source": [
        "## MLP from tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3emiAVruYdU0"
      },
      "source": [
        "Code is modified from the TP of our image course"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oak6mMlhYcbG",
        "outputId": "70764768-d384-4ff0-be6f-8716c7471e72"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# import tensorflow models\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIesWO9jdBqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1ace25-f3c4-453b-cf2b-f7ed610426f2"
      },
      "source": [
        "Y_train = tf.keras.utils.to_categorical(y_train)  # in order to convert y to a matrix with (num_examples, num_classes) (one-hot encoding)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test)  # in order to convert y to a matrix with (num_examples, num_classes) (one-hot encoding)\n",
        "print(Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3360, 5) (1120, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMDFn57FkUUI",
        "outputId": "7ce50acf-a851-4019-8a71-ddf3c2bba683"
      },
      "source": [
        "Y_train = Y_train[:,1:]\n",
        "Y_test = Y_test[:,1:]\n",
        "print(Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3360, 4) (1120, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU0mBwQTYnQV",
        "outputId": "40ea02e0-9505-453c-a967-04c02b210f5b"
      },
      "source": [
        "# Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer number of neurons\n",
        "n_hidden_2 = 256 # 2nd layer number of neurons\n",
        "n_hidden_3 = 128 # 2nd layer number of neurons\n",
        "\n",
        "n_input = X_train.shape[1]\n",
        "n_classes = 4\n",
        "# TO CODE BY STUDENTS\n",
        "\n",
        "\n",
        "model_mlp_multi_layer = Sequential()   # FILL IN STUDENTS\n",
        "model_mlp_multi_layer.add(Dense(n_hidden_1, input_shape=(n_input,)))\n",
        "model_mlp_multi_layer.add(BatchNormalization())\n",
        "model_mlp_multi_layer.add(Activation('relu'))\n",
        "model_mlp_multi_layer.add(Dense(n_hidden_2))\n",
        "model_mlp_multi_layer.add(BatchNormalization())\n",
        "model_mlp_multi_layer.add(Activation('relu'))\n",
        "model_mlp_multi_layer.add(Dense(n_hidden_3))\n",
        "model_mlp_multi_layer.add(BatchNormalization())\n",
        "model_mlp_multi_layer.add(Activation('relu'))\n",
        "model_mlp_multi_layer.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# create the loss and optimiser, use 'categorical_crossentropy' in loss\n",
        "learning_rate = 0.01\n",
        "model_mlp_multi_layer.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=learning_rate),metrics=[\"accuracy\"])\n",
        "\n",
        "# Run optimisation algorithm\n",
        "n_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "print('Training')\n",
        "model_mlp_multi_layer.fit(X_train_scale, Y_train, epochs=n_epochs,batch_size=batch_size) # TO FILL IN\n",
        "\n",
        "print('Testing')\n",
        "model_mlp_multi_layer.evaluate(X_test_scale,  Y_test, verbose=2) # TO FILL IN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "Epoch 1/100\n",
            "53/53 [==============================] - 2s 6ms/step - loss: 0.8110 - accuracy: 0.6513\n",
            "Epoch 2/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.8000\n",
            "Epoch 3/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8413\n",
            "Epoch 4/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8405\n",
            "Epoch 5/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3495 - accuracy: 0.8472\n",
            "Epoch 6/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3069 - accuracy: 0.8657\n",
            "Epoch 7/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.2820 - accuracy: 0.8664\n",
            "Epoch 8/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.2789 - accuracy: 0.8777\n",
            "Epoch 9/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.2571 - accuracy: 0.8845\n",
            "Epoch 10/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9015\n",
            "Epoch 11/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.2226 - accuracy: 0.9011\n",
            "Epoch 12/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.2312 - accuracy: 0.8969\n",
            "Epoch 13/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1858 - accuracy: 0.9221\n",
            "Epoch 14/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1770 - accuracy: 0.9192\n",
            "Epoch 15/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9051\n",
            "Epoch 16/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1961 - accuracy: 0.9124\n",
            "Epoch 17/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.9375\n",
            "Epoch 18/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1528 - accuracy: 0.9324\n",
            "Epoch 19/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1415 - accuracy: 0.9324\n",
            "Epoch 20/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1740 - accuracy: 0.9270\n",
            "Epoch 21/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 0.9433\n",
            "Epoch 22/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1684 - accuracy: 0.9314\n",
            "Epoch 23/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.9463\n",
            "Epoch 24/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1292 - accuracy: 0.9449\n",
            "Epoch 25/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9504\n",
            "Epoch 26/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1455 - accuracy: 0.9350\n",
            "Epoch 27/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.9463\n",
            "Epoch 28/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9475\n",
            "Epoch 29/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1295 - accuracy: 0.9488\n",
            "Epoch 30/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.9502\n",
            "Epoch 31/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9496\n",
            "Epoch 32/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1329 - accuracy: 0.9375\n",
            "Epoch 33/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9532\n",
            "Epoch 34/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9446\n",
            "Epoch 35/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9477\n",
            "Epoch 36/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9640\n",
            "Epoch 37/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.9542\n",
            "Epoch 38/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 0.9586\n",
            "Epoch 39/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9614\n",
            "Epoch 40/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9575\n",
            "Epoch 41/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9731\n",
            "Epoch 42/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.9548\n",
            "Epoch 43/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9620\n",
            "Epoch 44/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1003 - accuracy: 0.9617\n",
            "Epoch 45/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0932 - accuracy: 0.9651\n",
            "Epoch 46/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9740\n",
            "Epoch 47/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9701\n",
            "Epoch 48/100\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9604\n",
            "Epoch 49/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9701\n",
            "Epoch 50/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9675\n",
            "Epoch 51/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9730\n",
            "Epoch 52/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9595\n",
            "Epoch 53/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9655\n",
            "Epoch 54/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.9811\n",
            "Epoch 55/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.9734\n",
            "Epoch 56/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0664 - accuracy: 0.9748\n",
            "Epoch 57/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0672 - accuracy: 0.9737\n",
            "Epoch 58/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9767\n",
            "Epoch 59/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9808\n",
            "Epoch 60/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9700\n",
            "Epoch 61/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9588\n",
            "Epoch 62/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9739\n",
            "Epoch 63/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0581 - accuracy: 0.9742\n",
            "Epoch 64/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0661 - accuracy: 0.9746\n",
            "Epoch 65/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9750\n",
            "Epoch 66/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9799\n",
            "Epoch 67/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9786\n",
            "Epoch 68/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9802\n",
            "Epoch 69/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.9812\n",
            "Epoch 70/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.9755\n",
            "Epoch 71/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.9798\n",
            "Epoch 72/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9713\n",
            "Epoch 73/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0608 - accuracy: 0.9788\n",
            "Epoch 74/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9805\n",
            "Epoch 75/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9762\n",
            "Epoch 76/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.9730\n",
            "Epoch 77/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9787\n",
            "Epoch 78/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9833\n",
            "Epoch 79/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0557 - accuracy: 0.9773\n",
            "Epoch 80/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9879\n",
            "Epoch 81/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 0.9824\n",
            "Epoch 82/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.9800\n",
            "Epoch 83/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9787\n",
            "Epoch 84/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9789\n",
            "Epoch 85/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9829\n",
            "Epoch 86/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0457 - accuracy: 0.9798\n",
            "Epoch 87/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9860\n",
            "Epoch 88/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0543 - accuracy: 0.9828\n",
            "Epoch 89/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9884\n",
            "Epoch 90/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9723\n",
            "Epoch 91/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9781\n",
            "Epoch 92/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9816\n",
            "Epoch 93/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9854\n",
            "Epoch 94/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9919\n",
            "Epoch 95/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9888\n",
            "Epoch 96/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9737\n",
            "Epoch 97/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9867\n",
            "Epoch 98/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9875\n",
            "Epoch 99/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9870\n",
            "Epoch 100/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9828\n",
            "Testing\n",
            "35/35 - 0s - loss: 0.1175 - accuracy: 0.9589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1175299659371376, 0.9589285850524902]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBAOTRPW2cIP"
      },
      "source": [
        "The result of MLP is rather good, but if we compare it with boosting, the result of MLP is not good enough. Maybe if we finetune the model, the result will be better, but I think it won't be as good as boosting whose score is 0.998. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK0_Cemg2cJh"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNk75Fxt3N5f"
      },
      "source": [
        "In this dataset, the best model is boosting with RF feature selection method, and this model can get 0.998 f1 score, which is amazing. With good hyperparameters, the score of ensemble method can really be close to 1.\n",
        "\n",
        "The only disadvantage is that this model need a long time to train."
      ]
    }
  ]
}