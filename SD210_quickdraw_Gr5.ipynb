{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SD210_quickdraw_Gr5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ldlcgmuGAPT2",
        "Q5E98nhDARh1",
        "sxFrWQM7AyOs",
        "iE3BuhobA3ak",
        "9A-M_IodAkl1",
        "m2qe6BkNFLxf",
        "aIMz_0fuGnZn",
        "GtJEIj0UHEKX",
        "31h1wrwtH7JX",
        "t0wfH46xIGFB",
        "2uFkBJmpHPD9",
        "Tg-ZKgtYJX-T",
        "P0ZMjA9vJX-U",
        "zCF1e6LnHFlv",
        "eU7LpNxPWA37",
        "kMm9BFtNJ20a",
        "vopQQ_vxJ20b",
        "g8cVMuuEvCmC",
        "0Wix_NHmYZT-",
        "fr4gr6cxaz4v",
        "7VHpkJz_bj9l",
        "q3khTjy0yNx1",
        "FJCU-QR_gmzP",
        "dGHZm0Iq3XWe",
        "hEcd6J7q5la_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F7OxkYt7Ru2",
        "outputId": "16d6402e-09b5-418d-aa5d-cb7735c8a953"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "  gdd.download_file_from_google_drive(file_id='1viFv3uHGfNuq5olNqr80ekx9S42-9nNS',\n",
        "  dest_path='./G_5_ant.npy')\n",
        "  gdd.download_file_from_google_drive(file_id='1gumKga3nqan9WsBWcE_oxMSGc7nXXxtN',\n",
        "  dest_path='./G_5_grapes.npy')\n",
        "  gdd.download_file_from_google_drive(file_id='1a6ODxI7BxGkUH6qpRiyRa5bbOa-3hKE7',\n",
        "  dest_path='./test_image.npy')\n",
        "  gdd.download_file_from_google_drive(file_id='1yTInjFZl6VD71w7O6IZPxrX76xhR-8L9',\n",
        "  dest_path='./test_label.npy')\n",
        "else:\n",
        "  print('You are not using Colab. Please define working_dir with the absolute path to the folder where you downloaded the data')\n",
        "\n",
        "# Please modify working_dir only if you are using your Anaconda (and not Google Colab)\n",
        "# You should write the absolute path of your working directory with the data\n",
        "Working_directory=\"./\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1viFv3uHGfNuq5olNqr80ekx9S42-9nNS into ./G_5_ant.npy... Done.\n",
            "Downloading 1gumKga3nqan9WsBWcE_oxMSGc7nXXxtN into ./G_5_grapes.npy... Done.\n",
            "Downloading 1a6ODxI7BxGkUH6qpRiyRa5bbOa-3hKE7 into ./test_image.npy... Done.\n",
            "Downloading 1yTInjFZl6VD71w7O6IZPxrX76xhR-8L9 into ./test_label.npy... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsXDBrL-7ZlK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import paired_distances\n",
        "from sklearn.model_selection import  cross_val_score, cross_validate, GridSearchCV, KFold, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import decomposition\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "# this is needed to plot figures within the notebook\n",
        "%matplotlib inline \n",
        "np.random.seed(seed=666)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldlcgmuGAPT2"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKpyGEaL7c9p",
        "outputId": "37b045e5-5bed-46e5-c5a0-99b98d0d73bf"
      },
      "source": [
        "# read data\n",
        "ant = np.load('G_5_ant.npy')\n",
        "grapes = np.load('G_5_grapes.npy')\n",
        "X_test = np.load('test_image.npy')\n",
        "y_test = np.load('test_label.npy')\n",
        "print(ant.shape)\n",
        "print(grapes.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 784)\n",
            "(1000, 784)\n",
            "(1000, 784) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kVEvNcZVjbD",
        "outputId": "2f6975d7-a547-45a1-a5b3-795c616256c4"
      },
      "source": [
        "print(ant[0])\n",
        "print(grapes[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3  18   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  98 222 241  31   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3 236 255 249\n",
            " 181   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   7  13 132 254   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0 122 255   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0 122 255   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 122 255   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 122 255   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0 122 255   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 122 255   0\n",
            "   0   0   0  22 114 146 134  97  85  85  85  76  50  26   2   0   0   0\n",
            "   0   0   0   0   0   0   0 210 255 238 213 141 100 230 253 232 244 254\n",
            " 255 255 255 255 255 255 219  44   0   0   0   0   0   0   0   0   0 207\n",
            " 255 155 237 255 255 231  94   0  12 215 233 234  34  47  74  99 223 220\n",
            "  11   0   0   0   0   0   0   0  87 254 143   6 246 250 161   0   0   0\n",
            "   0 116 254 209   0   0   0   0  54 251 143   0   0   0   0   0   0   0\n",
            " 211 206   4   0 188 249 152   0   0   0   0  61 255 194   0   0   0   0\n",
            "   0 169 213   0   0   0   0   0   0   0 186 254 171 153 203 255 118   0\n",
            "   0   0   0 120 255 216  25   0   0   0   0 134 243   0   0   0   0   0\n",
            "   0   0   5 134 219 221 227 255 169  40 181  87   6 249 255 251 251 179\n",
            "  96  85  85 172 248   5   0   0   0   0   0   0   0   0   0   0   0 133\n",
            " 255 255 255 242 164 219 255 162 127 220 255 255 255 255 130   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   1  59  81 246 233 251 251 220 255\n",
            " 189  26  31  34  34  26   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0 239 198 244   7   0  87 241 233  64   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 239 191 254  28\n",
            "   0   0  35 200 148   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0 239 152 239 193   4   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 239 137\n",
            "  83 255 130   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0 239 137   0 148 253  16   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            " 239 137   0   4  57   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 223 122   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  17   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  81  90   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   1 245 255  59   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  21 255 255 117   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2 231 255\n",
            " 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0 154 255 188   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  75 255 188   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   8 247 188   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 235 188   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 235 188   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0 235 188   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 235 188   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 117  80  24\n",
            "   0   0   0   0   0   1  73 238 216 132  58   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0 140 255 255 255 224 167 111  34  59 208 255 255\n",
            " 255 255 244  36   0   0   0   0   0   0   0   0   0   0   0   0 123 114\n",
            "  49 106 161 217 255 253 214 216 250 128   0 108 255 227 221 226 238 224\n",
            " 142  47   0   0   0   0   0   0   0   0   0   0  36 174 254 255 255 255\n",
            " 248 178   0 208 255 193 157 153 137 167 246 255 183  10   0   0   0   0\n",
            "   0   0   0   3 215 236 120  68  68 111 245 255 243 249 251   6   0   0\n",
            "   0   0  14 108 251 125   0   0   0   0   0   0   0  27 255 102   0   0\n",
            "  10  48  48 254 255 255 246   0   0   0   0   0   0   0 206 174   0   0\n",
            "   0   0   0   0   0  15 250 195 153 153 218 255 221 255 255 246 253 185\n",
            " 230 133  10   0   0  32 240 168   0   0   0   0   0   0   0   0 116 221\n",
            " 221 221 246 248 249 255 241 255 255 255 255 255 242 178 136 210 236  27\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0 190 249 254 255 255 253\n",
            " 255 133 249 252 251 255 251 227  61   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  47 242 255 222 208 245 255  79 228 163   1  89 226 254\n",
            " 147   0   0   0   0   0   0   0   0   0   0   0   0   0 106 255 255 140\n",
            "   0 177 255 232 252 105 167   5  10 175 245   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0 118 255 255 121  56 252 203 250 132 244 203   4\n",
            "  74 234 206   0   0   0   0   0   0   0   0   0   0   0   0   0 105 255\n",
            " 253 188 230 218   9   7  83 255  65 156 255 203  30   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  20  92 128 254 204  38   0   0  93 255\n",
            " 255 250 125   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  65 119  46   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrTorZ9RVpM5"
      },
      "source": [
        "The data are rather sparse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "JMyxkD1wQYFF",
        "outputId": "cbb843c8-3c67-452a-e2ba-8fe5e527ca2c"
      },
      "source": [
        "# visualize some train data\n",
        "num = 4\n",
        "\n",
        "for i in range(num):\n",
        "  plt.subplot(num, 2, 2*i+1)\n",
        "  plt.imshow(ant[i].reshape(28,28), cmap='gray')\n",
        "  plt.axis('off')\n",
        "  if i == 0:\n",
        "    plt.title('ant')\n",
        "  plt.subplot(num, 2, (i+1)*2)\n",
        "  plt.imshow(grapes[i].reshape(28,28), cmap='gray')\n",
        "  plt.axis('off')\n",
        "  if i == 0:\n",
        "    plt.title('grapes')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqdy9l4lS67c"
      },
      "source": [
        "**Comment:**\n",
        "\n",
        "There are too many features, and too many nuisance variables. Therefore, it's necessary use some methods to reduce the dimensions later.\n",
        "\n",
        "One of the difficulties is too select the most important features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx-kXzYb7nhV"
      },
      "source": [
        "# label 0 means ant, 1 means grapes\n",
        "\n",
        "X = np.vstack((ant, grapes))\n",
        "y = np.zeros(2000)\n",
        "y[1000:] = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVmfrn4Z-mBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c804bd78-aa64-4c31-d49f-193e25664989"
      },
      "source": [
        "# shuffle the data\n",
        "indices = np.random.permutation(X.shape[0])\n",
        "print(len(indices))\n",
        "X_train = X[indices, :]\n",
        "y_train = y[indices]\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "(2000, 784) (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5E98nhDARh1"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxFrWQM7AyOs"
      },
      "source": [
        "## Scale data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MydmdoayqxTr"
      },
      "source": [
        "First scale the data, because if we want to use some methods like PCA, it's necessary to center the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2WsoR2SA002"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scale = scaler.transform(X_train)\n",
        "X_test_scale = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE3BuhobA3ak"
      },
      "source": [
        "## Feature selections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOxSGsW1Ag3F"
      },
      "source": [
        "If we use some traditional ML methods, it's important to reduce the dimension by removing most nuisance variables. Otherwise, the execution time is too large and the performance won't be good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A-M_IodAkl1"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vgTIikDEhZX"
      },
      "source": [
        "The simplest way is to apply PCA to select features\n",
        "\n",
        "By doing some experience, we find we cannot choose a large number of components for PCA. If n_components is large, there may be too many nuisance variables, the performance of our model will decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqXkkiz6_JRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9216f0-6792-4c3e-9e25-88bdcee2a94f"
      },
      "source": [
        "pca = PCA(n_components=200,svd_solver='randomized', whiten=True)\n",
        "pca.fit(X_train_scale)\n",
        "\n",
        "X_train_pca = pca.transform(X_train_scale)\n",
        "X_test_pca = pca.transform(X_test_scale)\n",
        "print(np.sum(pca.explained_variance_ratio_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.881367534154416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2qe6BkNFLxf"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1NEN5MVF3av"
      },
      "source": [
        "We can also use RF to select important features by using the feature_importance proporty.\n",
        "\n",
        "Here we choose the 300 features whose feature_importance are large."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvxJB8UI_Lve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d2a6d1-685a-4b9d-ce34-a9e6a3c90c49"
      },
      "source": [
        "n_component = 300\n",
        "\n",
        "model = RandomForestClassifier(n_jobs=8, random_state=0)\n",
        "model.fit(X_train_scale, y_train.ravel())\n",
        "\n",
        "feature_importance = model.feature_importances_\n",
        "index = np.argsort(feature_importance)[-1:-n_component-1:-1]\n",
        "\n",
        "X_train_RF = X_train_scale[:, index]\n",
        "X_test_RF = X_test_scale[:, index]\n",
        "\n",
        "print(np.sum(feature_importance[index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.816801155670825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIMz_0fuGnZn"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtJEIj0UHEKX"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8IQx0HCUByc"
      },
      "source": [
        "SVM is a rather simple but useful classifier, so we try SVM first.\n",
        "\n",
        "I use RandomizedSearchCV, because it's faster than GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqUn1eFqGiGm"
      },
      "source": [
        "p_grid_lsvm = {'C': [1e-3,1e-2,0.05,1e-1,0.5,1,2,5,1e1,1e2,15,20,40,60,80,120,140],\n",
        "                'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 1,2,4,8,10,15,20,30,40,50,60], }\n",
        "Lsvm = SVC(kernel='rbf')\n",
        "grid_lsvm = RandomizedSearchCV(estimator=Lsvm, param_distributions=p_grid_lsvm, scoring='f1', cv=5, n_jobs=8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_QSo7rUOuK"
      },
      "source": [
        "Here, we want to try the PCA preprocessed data and RF preprocessed data to compare the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31h1wrwtH7JX"
      },
      "source": [
        "### PCA preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMObSEI-H6CH",
        "outputId": "986c0038-3fcc-44ba-b653-485d1baec4c5"
      },
      "source": [
        "grid_lsvm.fit(X_train_pca, y_train.ravel())\n",
        "test_score = grid_lsvm.score(X_test_pca, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_lsvm.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_lsvm.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best training Score: 0.8532808889985759\n",
            "Best training params: {'gamma': 0.005, 'C': 10.0}\n",
            "Test score: 0.8275862068965517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0wfH46xIGFB"
      },
      "source": [
        "### RF preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prs6W0qeI1AZ",
        "outputId": "c6391734-3b7e-4c00-85d9-f3b9f608c858"
      },
      "source": [
        "grid_lsvm.fit(X_train_RF, y_train.ravel())\n",
        "test_score = grid_lsvm.score(X_test_RF, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_lsvm.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_lsvm.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best training Score: 0.8908932499278963\n",
            "Best training params: {'gamma': 0.005, 'C': 80}\n",
            "Test score: 0.8642714570858283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "admzbT6DshVD"
      },
      "source": [
        "Comparing the 2 results, we can find that the SVM can have a very good result on this dataset, and the RF preprocessed data can have larger train and test scores. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uFkBJmpHPD9"
      },
      "source": [
        "## Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9sPVXZHHDEN"
      },
      "source": [
        "XGB = XGBClassifier()\n",
        "p_grid_xgb = dict(\n",
        "    max_depth = [4, 5, 6, 7],\n",
        "    learning_rate = np.linspace(0.03, 0.3, 10),\n",
        "    n_estimators = [100, 200]\n",
        ")\n",
        "\n",
        "grid_xgb = RandomizedSearchCV(estimator=XGB, param_distributions=p_grid_xgb, scoring='f1', cv=5, n_jobs = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg-ZKgtYJX-T"
      },
      "source": [
        "### PCA preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbj6CiAgJX-T",
        "outputId": "2b2943d7-523a-4ad6-9c8a-1b616f33e4ca"
      },
      "source": [
        "grid_xgb.fit(X_train_pca, y_train.ravel())\n",
        "test_score = grid_xgb.score(X_test_pca, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_xgb.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_xgb.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best training Score: 0.8786026537458913\n",
            "Best training params: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.21000000000000002}\n",
            "Test score: 0.850597609561753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0ZMjA9vJX-U"
      },
      "source": [
        "### RF preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJeL52MoJX-U",
        "outputId": "116ab215-7934-4b72-ea78-b64d9297431c"
      },
      "source": [
        "grid_xgb.fit(X_train_RF, y_train.ravel())\n",
        "test_score = grid_xgb.score(X_test_RF, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_xgb.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_xgb.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best training Score: 0.8879293681811647\n",
            "Best training params: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.12000000000000001}\n",
            "Test score: 0.8519637462235649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqWrCnJrtG8r"
      },
      "source": [
        "I find on the Internet that the boosting method will generally better than SVM. But here, the result of boosting methode is even slightly lower than SVM. Maybe it's because I have choose a good candidate hyperparameter list for boosting, while I choose a large candidate list for SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCF1e6LnHFlv"
      },
      "source": [
        "## MLP from sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2PJC63Uus2y"
      },
      "source": [
        "In our course, we use tensorflow to implement MLP, but I also find that sklearn has a MLPClassifier, so I just want to have a try."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOOWMFgpJnQI"
      },
      "source": [
        "MLP = MLPClassifier(activation='relu', alpha=1e-4, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(256,256,128), \n",
        "       learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
        "       tol=0.0001, validation_fraction=0.1,\n",
        "       warm_start=False, verbose=10)\n",
        "\n",
        "p_grid_mlp = {'solver': ['adam', 'sgd'], 'learning_rate' : ['adaptive', 'constant']}\n",
        "grid_mlp = RandomizedSearchCV(estimator=MLP, param_distributions=p_grid_mlp, scoring='f1', cv=5, n_jobs = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU7LpNxPWA37"
      },
      "source": [
        "### Original dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leijssE3WJej",
        "outputId": "ebdf8eea-48aa-4236-dd6b-97f14cf47284"
      },
      "source": [
        "grid_mlp.fit(X_train_scale, y_train.ravel())\n",
        "test_score = grid_mlp.score(X_test_scale, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_mlp.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_mlp.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.63299174\n",
            "Iteration 2, loss = 0.39612204\n",
            "Iteration 3, loss = 0.32608897\n",
            "Iteration 4, loss = 0.28507113\n",
            "Iteration 5, loss = 0.25161340\n",
            "Iteration 6, loss = 0.22692375\n",
            "Iteration 7, loss = 0.20223415\n",
            "Iteration 8, loss = 0.17961521\n",
            "Iteration 9, loss = 0.15810022\n",
            "Iteration 10, loss = 0.13930143\n",
            "Iteration 11, loss = 0.12122790\n",
            "Iteration 12, loss = 0.10547915\n",
            "Iteration 13, loss = 0.08988902\n",
            "Iteration 14, loss = 0.07705874\n",
            "Iteration 15, loss = 0.06559039\n",
            "Iteration 16, loss = 0.05511256\n",
            "Iteration 17, loss = 0.04712672\n",
            "Iteration 18, loss = 0.03945287\n",
            "Iteration 19, loss = 0.03312853\n",
            "Iteration 20, loss = 0.02789043\n",
            "Iteration 21, loss = 0.02379175\n",
            "Iteration 22, loss = 0.02017064\n",
            "Iteration 23, loss = 0.01710608\n",
            "Iteration 24, loss = 0.01478470\n",
            "Iteration 25, loss = 0.01272773\n",
            "Iteration 26, loss = 0.01110543\n",
            "Iteration 27, loss = 0.00972781\n",
            "Iteration 28, loss = 0.00857734\n",
            "Iteration 29, loss = 0.00769563\n",
            "Iteration 30, loss = 0.00685997\n",
            "Iteration 31, loss = 0.00618679\n",
            "Iteration 32, loss = 0.00562458\n",
            "Iteration 33, loss = 0.00516134\n",
            "Iteration 34, loss = 0.00475321\n",
            "Iteration 35, loss = 0.00438660\n",
            "Iteration 36, loss = 0.00406546\n",
            "Iteration 37, loss = 0.00379123\n",
            "Iteration 38, loss = 0.00353775\n",
            "Iteration 39, loss = 0.00332285\n",
            "Iteration 40, loss = 0.00311527\n",
            "Iteration 41, loss = 0.00295155\n",
            "Iteration 42, loss = 0.00279089\n",
            "Iteration 43, loss = 0.00264404\n",
            "Iteration 44, loss = 0.00252130\n",
            "Iteration 45, loss = 0.00240147\n",
            "Iteration 46, loss = 0.00230659\n",
            "Iteration 47, loss = 0.00218391\n",
            "Iteration 48, loss = 0.00209467\n",
            "Iteration 49, loss = 0.00201218\n",
            "Iteration 50, loss = 0.00193123\n",
            "Iteration 51, loss = 0.00185788\n",
            "Iteration 52, loss = 0.00178976\n",
            "Iteration 53, loss = 0.00172553\n",
            "Iteration 54, loss = 0.00166779\n",
            "Iteration 55, loss = 0.00161310\n",
            "Iteration 56, loss = 0.00156095\n",
            "Iteration 57, loss = 0.00151347\n",
            "Iteration 58, loss = 0.00146872\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Best training Score: 0.8749452521137719\n",
            "Best training params: {'solver': 'sgd', 'learning_rate': 'constant'}\n",
            "Test score: 0.8414755732801595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMm9BFtNJ20a"
      },
      "source": [
        "### PCA preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5zlC_w6J20b",
        "outputId": "20a8482f-4bf6-4226-d58e-8afb8ac9daec"
      },
      "source": [
        "grid_mlp.fit(X_train_pca, y_train.ravel())\n",
        "test_score = grid_mlp.score(X_test_pca, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_mlp.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_mlp.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.89814494\n",
            "Iteration 2, loss = 0.30825331\n",
            "Iteration 3, loss = 0.18784133\n",
            "Iteration 4, loss = 0.08140631\n",
            "Iteration 5, loss = 0.02977282\n",
            "Iteration 6, loss = 0.01633751\n",
            "Iteration 7, loss = 0.01709274\n",
            "Iteration 8, loss = 0.02511490\n",
            "Iteration 9, loss = 0.03686444\n",
            "Iteration 10, loss = 0.05250993\n",
            "Iteration 11, loss = 0.02693690\n",
            "Iteration 12, loss = 0.01859762\n",
            "Iteration 13, loss = 0.01003171\n",
            "Iteration 14, loss = 0.00684278\n",
            "Iteration 15, loss = 0.00831493\n",
            "Iteration 16, loss = 0.00493901\n",
            "Iteration 17, loss = 0.00717676\n",
            "Iteration 18, loss = 0.01940204\n",
            "Iteration 19, loss = 0.02295096\n",
            "Iteration 20, loss = 0.06523056\n",
            "Iteration 21, loss = 0.04835995\n",
            "Iteration 22, loss = 0.01980844\n",
            "Iteration 23, loss = 0.00842801\n",
            "Iteration 24, loss = 0.00442902\n",
            "Iteration 25, loss = 0.00641902\n",
            "Iteration 26, loss = 0.00194156\n",
            "Iteration 27, loss = 0.00103644\n",
            "Iteration 28, loss = 0.00060118\n",
            "Iteration 29, loss = 0.00052571\n",
            "Iteration 30, loss = 0.00049259\n",
            "Iteration 31, loss = 0.00047749\n",
            "Iteration 32, loss = 0.00047067\n",
            "Iteration 33, loss = 0.00046524\n",
            "Iteration 34, loss = 0.00046184\n",
            "Iteration 35, loss = 0.00045927\n",
            "Iteration 36, loss = 0.00045704\n",
            "Iteration 37, loss = 0.00045541\n",
            "Iteration 38, loss = 0.00045385\n",
            "Iteration 39, loss = 0.00045248\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Best training Score: 0.836273769081683\n",
            "Best training params: {'solver': 'adam', 'learning_rate': 'adaptive'}\n",
            "Test score: 0.8153998025666338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vopQQ_vxJ20b"
      },
      "source": [
        "### RF preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekf5CwfKJ20b",
        "outputId": "2fb54630-94e8-43af-be04-fcc7331757c1"
      },
      "source": [
        "grid_mlp.fit(X_train_RF, y_train.ravel())\n",
        "test_score = grid_mlp.score(X_test_RF, y_test.ravel())\n",
        "\n",
        "print(\"Best training Score: {}\".format(grid_mlp.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_mlp.best_params_))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.03740029\n",
            "Iteration 2, loss = 0.29554113\n",
            "Iteration 3, loss = 0.25376441\n",
            "Iteration 4, loss = 0.21105941\n",
            "Iteration 5, loss = 0.17371613\n",
            "Iteration 6, loss = 0.13824737\n",
            "Iteration 7, loss = 0.10085602\n",
            "Iteration 8, loss = 0.04891018\n",
            "Iteration 9, loss = 0.03979319\n",
            "Iteration 10, loss = 0.04057065\n",
            "Iteration 11, loss = 0.03821473\n",
            "Iteration 12, loss = 0.04321920\n",
            "Iteration 13, loss = 0.02603392\n",
            "Iteration 14, loss = 0.01904863\n",
            "Iteration 15, loss = 0.01206219\n",
            "Iteration 16, loss = 0.00912584\n",
            "Iteration 17, loss = 0.00521939\n",
            "Iteration 18, loss = 0.00369708\n",
            "Iteration 19, loss = 0.00224399\n",
            "Iteration 20, loss = 0.00089506\n",
            "Iteration 21, loss = 0.00194352\n",
            "Iteration 22, loss = 0.01870870\n",
            "Iteration 23, loss = 0.01790862\n",
            "Iteration 24, loss = 0.02428901\n",
            "Iteration 25, loss = 0.01426579\n",
            "Iteration 26, loss = 0.01538837\n",
            "Iteration 27, loss = 0.02072495\n",
            "Iteration 28, loss = 0.01946963\n",
            "Iteration 29, loss = 0.02087605\n",
            "Iteration 30, loss = 0.01392759\n",
            "Iteration 31, loss = 0.01083154\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Best training Score: 0.8748740423327821\n",
            "Best training params: {'solver': 'adam', 'learning_rate': 'adaptive'}\n",
            "Test score: 0.8414755732801595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8cVMuuEvCmC"
      },
      "source": [
        "### Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfvD33tmvG_5"
      },
      "source": [
        "From this 3 results, we can find that:\n",
        "\n",
        "1. For the methods like MLP, if we have a deep network, we can directly use the original data as input, and the result is as good as the result of RF preprocessed data.\n",
        "\n",
        "2. Maybe I haven't selected a good hyperparameter, the best performance of MLP is even lower to SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wix_NHmYZT-"
      },
      "source": [
        "## MLP from tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3emiAVruYdU0"
      },
      "source": [
        "Code is modified from the TP of our image course"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oak6mMlhYcbG",
        "outputId": "9ec817db-0a46-4fae-a368-049a1c14f9bf"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# import tensorflow models\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU0mBwQTYnQV",
        "outputId": "f95e472b-a936-497a-f63d-60a0fd6efb75"
      },
      "source": [
        "# Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer number of neurons\n",
        "n_hidden_2 = 256 # 2nd layer number of neurons\n",
        "n_hidden_3 = 128 # 2nd layer number of neurons\n",
        "\n",
        "n_input = X_train.shape[1]\n",
        "\n",
        "# TO CODE BY STUDENTS\n",
        "\n",
        "\n",
        "model_mlp_multi_layer = Sequential()   # FILL IN STUDENTS\n",
        "model_mlp_multi_layer.add(Dense(n_hidden_1, input_shape=(n_input,)))\n",
        "model_mlp_multi_layer.add(BatchNormalization())\n",
        "model_mlp_multi_layer.add(Activation('relu'))\n",
        "model_mlp_multi_layer.add(Dense(n_hidden_2))\n",
        "model_mlp_multi_layer.add(BatchNormalization())\n",
        "model_mlp_multi_layer.add(Activation('relu'))\n",
        "model_mlp_multi_layer.add(Dense(n_hidden_3))\n",
        "model_mlp_multi_layer.add(BatchNormalization())\n",
        "model_mlp_multi_layer.add(Activation('relu'))\n",
        "model_mlp_multi_layer.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# create the loss and optimiser, use 'binary_crossentropy' in loss\n",
        "learning_rate = 0.01\n",
        "model_mlp_multi_layer.compile(loss=\"binary_crossentropy\", optimizer=optimizers.Adam(lr=learning_rate),metrics=[\"accuracy\"])\n",
        "\n",
        "# Run optimisation algorithm\n",
        "n_epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "print('Training')\n",
        "model_mlp_multi_layer.fit(X_train_scale, y_train, epochs=n_epochs,batch_size=batch_size) # TO FILL IN\n",
        "\n",
        "print('Testing')\n",
        "y_pre = model_mlp_multi_layer.predict(X_test_scale) # TO FILL IN\n",
        "print(y_pre.shape)\n",
        "y_pre = np.around(y_pre)\n",
        "\n",
        "print(f1_score(y_test, y_pre.reshape(-1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 4s 4ms/step - loss: 0.4543 - accuracy: 0.7882\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2207 - accuracy: 0.9186\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9399\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9545\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9748\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9719\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9825\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9681\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9875\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9840\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9924\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9840\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9917\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9940\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9920\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9888\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9865\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9893\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9941\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9937\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9975\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9954\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9969\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9969\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9962\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9938\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9938\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9981\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9977\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9939\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9941\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9983\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9985\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9991\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9937\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9983\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9906\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9984\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9990\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 7.3985e-04 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9999\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9996\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9756\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9914\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9950\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9950\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9998\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9987\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 6.5997e-04 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 8.8280e-04 - accuracy: 0.9999\n",
            "Testing\n",
            "(1000, 1)\n",
            "0.8425357873210634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCJh4qXsyfp6"
      },
      "source": [
        "It seems that the best performance of MLP is even lower than the best performance of SVM.\n",
        "\n",
        "This is strange, because I thought the MLP method will generally be better than SVM. Maybe it's still because of the hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr4gr6cxaz4v"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS4OwQcqyz0w"
      },
      "source": [
        "This dataset is a set of pictures, so it's possible we use a simple CNN to extract the features just like MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5RbSeZgiZO3"
      },
      "source": [
        "The code is modified from our image class project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOOkP0XZbuI6"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "import sys\n",
        "import cv2\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VHpkJz_bj9l"
      },
      "source": [
        "### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDKjAicXe_ao"
      },
      "source": [
        "X_train = X_train.reshape((-1, 28, 28))\n",
        "X_test = X_test.reshape((-1, 28, 28))\n",
        "\n",
        "X_train = np.array(X_train, dtype='uint8')\n",
        "X_test = np.array(X_test, dtype='uint8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdI_icJ9o4Zc"
      },
      "source": [
        "# data augmentation\n",
        "def random_horizontal_flip(imgs):\n",
        "    if random.random() < 0.5:\n",
        "        imgs = np.flip(imgs, axis=1).copy()\n",
        "    return imgs\n",
        "\n",
        "def random_rotate(imgs):\n",
        "    max_angle = 20\n",
        "    angle = random.random() * 2 * max_angle - max_angle\n",
        "    \n",
        "    w, h = imgs.shape[:2]\n",
        "    rotation_matrix = cv2.getRotationMatrix2D((h / 2, w / 2), angle, 1)\n",
        "    img_rotation = cv2.warpAffine(imgs, rotation_matrix, (h, w))\n",
        "    imgs = img_rotation\n",
        "    return imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yInXJhmmiYHQ"
      },
      "source": [
        "class trainset(data.Dataset):\n",
        "    def __init__(self, train_data, train_label):\n",
        "        self.train_data = train_data\n",
        "        self.train_label = train_label\n",
        "    def __getitem__(self, index):\n",
        "        img = self.train_data[index]\n",
        "        img = random_horizontal_flip(img)\n",
        "        img = random_rotate(img)\n",
        "        img = torch.from_numpy(img)\n",
        "        img = img.unsqueeze(0)\n",
        "        img = transforms.ToPILImage()(img)\n",
        "        img = transforms.ToTensor()(img)\n",
        "        img = transforms.Normalize((0.1307,), (0.3081,))(img)\n",
        "        target = self.train_label[index]\n",
        "        target = torch.tensor(target).long()\n",
        "        return img,target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.train_data.shape[0]\n",
        "\n",
        "class testset(data.Dataset):\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "    def __getitem__(self, index):\n",
        "        img = self.test_data[index]\n",
        "        img = torch.from_numpy(img)\n",
        "        img = img.unsqueeze(0)\n",
        "        img = transforms.ToPILImage()(img)\n",
        "        img = transforms.ToTensor()(img)\n",
        "        img = transforms.Normalize((0.1307,), (0.3081,))(img)\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.test_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFFQqinWklbZ"
      },
      "source": [
        "Trainset = trainset(X_train, y_train)\n",
        "Testset = testset(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-lgR08ggGW_"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        Trainset,\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        drop_last=False,\n",
        "        pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        Testset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3khTjy0yNx1"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNgoBA6RyQpW"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(12544, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        # print(x.shape)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        # output = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJCU-QR_gmzP"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awM-V8w9fpqI"
      },
      "source": [
        "model = Net().cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LQToAvS03Nt"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "max_epoch = 25\n",
        "\n",
        "train_loss = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJLCIKTqgxJe",
        "outputId": "a2ae8857-306e-4d51-c9e0-32e0372d315c"
      },
      "source": [
        "for epoch in range(max_epoch):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  for batch_idx, (imgs, gt) in enumerate(train_loader):\n",
        "\n",
        "        imgs = Variable(imgs.cuda())\n",
        "        gt = Variable(gt.cuda())\n",
        "\n",
        "        \n",
        "        outputs = model(imgs)\n",
        "\n",
        "        loss = criterion(outputs, gt)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        if batch_idx % 10 == 0:\n",
        "          print(\"Epoch \"+str(epoch)+\": \"+str(batch_idx) + \" loss: \" + str(loss.item()))\n",
        "  train_loss.append(epoch_loss/(batch_idx+1))\n",
        "  scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 0 loss: 0.6994697451591492\n",
            "Epoch 0: 10 loss: 0.47836965322494507\n",
            "Epoch 0: 20 loss: 0.3933480978012085\n",
            "Epoch 0: 30 loss: 0.34025445580482483\n",
            "Epoch 1: 0 loss: 0.18642288446426392\n",
            "Epoch 1: 10 loss: 0.22465880215168\n",
            "Epoch 1: 20 loss: 0.18164950609207153\n",
            "Epoch 1: 30 loss: 0.31143060326576233\n",
            "Epoch 2: 0 loss: 0.2045906037092209\n",
            "Epoch 2: 10 loss: 0.21520139276981354\n",
            "Epoch 2: 20 loss: 0.2564404010772705\n",
            "Epoch 2: 30 loss: 0.28965261578559875\n",
            "Epoch 3: 0 loss: 0.19591739773750305\n",
            "Epoch 3: 10 loss: 0.18788085877895355\n",
            "Epoch 3: 20 loss: 0.18301177024841309\n",
            "Epoch 3: 30 loss: 0.09504547715187073\n",
            "Epoch 4: 0 loss: 0.29785266518592834\n",
            "Epoch 4: 10 loss: 0.1789146065711975\n",
            "Epoch 4: 20 loss: 0.07107450813055038\n",
            "Epoch 4: 30 loss: 0.1857064962387085\n",
            "Epoch 5: 0 loss: 0.14215466380119324\n",
            "Epoch 5: 10 loss: 0.1428649127483368\n",
            "Epoch 5: 20 loss: 0.14243733882904053\n",
            "Epoch 5: 30 loss: 0.16629721224308014\n",
            "Epoch 6: 0 loss: 0.11643721908330917\n",
            "Epoch 6: 10 loss: 0.10955256223678589\n",
            "Epoch 6: 20 loss: 0.12472014129161835\n",
            "Epoch 6: 30 loss: 0.12770293653011322\n",
            "Epoch 7: 0 loss: 0.10340526700019836\n",
            "Epoch 7: 10 loss: 0.14292342960834503\n",
            "Epoch 7: 20 loss: 0.26899752020835876\n",
            "Epoch 7: 30 loss: 0.19314195215702057\n",
            "Epoch 8: 0 loss: 0.18153011798858643\n",
            "Epoch 8: 10 loss: 0.09204702079296112\n",
            "Epoch 8: 20 loss: 0.09037286043167114\n",
            "Epoch 8: 30 loss: 0.1783325970172882\n",
            "Epoch 9: 0 loss: 0.13407471776008606\n",
            "Epoch 9: 10 loss: 0.031014420092105865\n",
            "Epoch 9: 20 loss: 0.13426367938518524\n",
            "Epoch 9: 30 loss: 0.16839520633220673\n",
            "Epoch 10: 0 loss: 0.09223379194736481\n",
            "Epoch 10: 10 loss: 0.06956835091114044\n",
            "Epoch 10: 20 loss: 0.1301300972700119\n",
            "Epoch 10: 30 loss: 0.03006616048514843\n",
            "Epoch 11: 0 loss: 0.14880569279193878\n",
            "Epoch 11: 10 loss: 0.2229115515947342\n",
            "Epoch 11: 20 loss: 0.04229181632399559\n",
            "Epoch 11: 30 loss: 0.12771059572696686\n",
            "Epoch 12: 0 loss: 0.14633019268512726\n",
            "Epoch 12: 10 loss: 0.12978795170783997\n",
            "Epoch 12: 20 loss: 0.18650449812412262\n",
            "Epoch 12: 30 loss: 0.047766998410224915\n",
            "Epoch 13: 0 loss: 0.08098787814378738\n",
            "Epoch 13: 10 loss: 0.13255031406879425\n",
            "Epoch 13: 20 loss: 0.3244597911834717\n",
            "Epoch 13: 30 loss: 0.10182157903909683\n",
            "Epoch 14: 0 loss: 0.08152974396944046\n",
            "Epoch 14: 10 loss: 0.16522075235843658\n",
            "Epoch 14: 20 loss: 0.1402774602174759\n",
            "Epoch 14: 30 loss: 0.0730925127863884\n",
            "Epoch 15: 0 loss: 0.08724917471408844\n",
            "Epoch 15: 10 loss: 0.19244611263275146\n",
            "Epoch 15: 20 loss: 0.04842078685760498\n",
            "Epoch 15: 30 loss: 0.1215955913066864\n",
            "Epoch 16: 0 loss: 0.12217367440462112\n",
            "Epoch 16: 10 loss: 0.0999101772904396\n",
            "Epoch 16: 20 loss: 0.11801353842020035\n",
            "Epoch 16: 30 loss: 0.05113477259874344\n",
            "Epoch 17: 0 loss: 0.04421895742416382\n",
            "Epoch 17: 10 loss: 0.15359827876091003\n",
            "Epoch 17: 20 loss: 0.07712136954069138\n",
            "Epoch 17: 30 loss: 0.11407169699668884\n",
            "Epoch 18: 0 loss: 0.051036812365055084\n",
            "Epoch 18: 10 loss: 0.042343419045209885\n",
            "Epoch 18: 20 loss: 0.05036020278930664\n",
            "Epoch 18: 30 loss: 0.051187269389629364\n",
            "Epoch 19: 0 loss: 0.0338028147816658\n",
            "Epoch 19: 10 loss: 0.07354331016540527\n",
            "Epoch 19: 20 loss: 0.10973884165287018\n",
            "Epoch 19: 30 loss: 0.04610731080174446\n",
            "Epoch 20: 0 loss: 0.11704863607883453\n",
            "Epoch 20: 10 loss: 0.095128633081913\n",
            "Epoch 20: 20 loss: 0.08245224505662918\n",
            "Epoch 20: 30 loss: 0.16091211140155792\n",
            "Epoch 21: 0 loss: 0.11447234451770782\n",
            "Epoch 21: 10 loss: 0.20922794938087463\n",
            "Epoch 21: 20 loss: 0.12292125821113586\n",
            "Epoch 21: 30 loss: 0.08622074872255325\n",
            "Epoch 22: 0 loss: 0.10491745173931122\n",
            "Epoch 22: 10 loss: 0.06957218050956726\n",
            "Epoch 22: 20 loss: 0.10003260523080826\n",
            "Epoch 22: 30 loss: 0.16614757478237152\n",
            "Epoch 23: 0 loss: 0.15336531400680542\n",
            "Epoch 23: 10 loss: 0.31560614705085754\n",
            "Epoch 23: 20 loss: 0.05887605994939804\n",
            "Epoch 23: 30 loss: 0.039873555302619934\n",
            "Epoch 24: 0 loss: 0.06158428639173508\n",
            "Epoch 24: 10 loss: 0.12447895854711533\n",
            "Epoch 24: 20 loss: 0.06196282058954239\n",
            "Epoch 24: 30 loss: 0.08570149540901184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "1Vj8vq12o9gE",
        "outputId": "1b57caff-8306-4460-fc89-fe12f5ad68cf"
      },
      "source": [
        "plt.plot(train_loss, marker='*')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGHZm0Iq3XWe"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lECKnOL23KKj"
      },
      "source": [
        "model = model.cuda()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "for idx, img in enumerate(test_loader):\n",
        "  with torch.no_grad():\n",
        "    img = Variable(img.cuda())\n",
        "    \n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    outputs = model(img)\n",
        "\n",
        "    outputs = outputs.squeeze(0).cpu().detach().numpy().astype(np.float32)\n",
        "\n",
        "    result = np.argmax(outputs)\n",
        "\n",
        "    y_pred.append(result)\n",
        "    torch.cuda.synchronize()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eL4MB5M4OY2",
        "outputId": "2abae8d8-ceb8-4b41-ccf4-72fa43f5c81b"
      },
      "source": [
        "f1_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9243353783231084"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rca7TWuhWn0A"
      },
      "source": [
        "The result is much than the other methods just as I expected.\n",
        "\n",
        "This is because CNN can better extract the features from images. CNN can preserve the position information, which is very important for images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEcd6J7q5la_"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4yKwfn45oRn"
      },
      "source": [
        "The CNN method can obtain a f1 score 0.9243353783231084, which is much higher than the other methods.\n",
        "\n",
        "It seems the CNN based deep learning is the best model for computer vision (maybe now transformer is better, I'm not sure)"
      ]
    }
  ]
}